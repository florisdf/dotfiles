//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-22053397
// Driver 375.66
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_30, texmode_independent
.address_size 64

	// .globl	DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope

.entry DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope(
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_0,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_1,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_2,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_3,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_4,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_5,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_6,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_7,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_8,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_9
)
{
	.reg .pred 	%p<212>;
	.reg .f32 	%f<13>;
	.reg .b32 	%r<383>;
	.reg .f64 	%fd<1878>;
	.reg .b64 	%rd<70>;


	ld.param.u64 	%rd10, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_4];
	ld.param.u64 	%rd11, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_5];
	ld.param.u64 	%rd12, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_6];
	ld.param.u64 	%rd13, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_7];
	ld.param.u64 	%rd14, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_8];
	ld.param.u64 	%rd15, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_9];
	mov.b32	%r144, %envreg3;
	mov.u32 	%r145, %ctaid.x;
	mov.u32 	%r146, %ntid.x;
	mad.lo.s32 	%r147, %r145, %r146, %r144;
	mov.u32 	%r148, %tid.x;
	add.s32 	%r1, %r147, %r148;
	mov.f64 	%fd1792, 0d0000000000000000;
	mov.f64 	%fd1785, %fd1792;
	mov.f64 	%fd1778, %fd1792;
	mov.f64 	%fd1793, %fd1792;
	mov.f64 	%fd1786, %fd1792;
	mov.f64 	%fd1779, %fd1792;
	mov.u32 	%r331, 0;
	setp.gt.s32	%p1, %r1, 5;
	@%p1 bra 	BB0_6;

	mov.u32 	%r371, %r1;

BB0_2:
	mov.u32 	%r2, %r371;
	mov.f64 	%fd1788, %fd1793;
	mov.f64 	%fd3, %fd1788;
	mov.f64 	%fd1781, %fd1786;
	mov.f64 	%fd2, %fd1781;
	mov.f64 	%fd1774, %fd1779;
	mov.f64 	%fd1, %fd1774;
	mul.wide.s32 	%rd16, %r2, 8;
	add.s64 	%rd17, %rd15, %rd16;
	add.s64 	%rd18, %rd14, %rd16;
	ld.global.f64 	%fd4, [%rd18];
	ld.global.f64 	%fd5, [%rd17];
	abs.f64 	%fd265, %fd5;
	setp.gtu.f64	%p2, %fd265, 0d7FF0000000000000;
	mov.f64 	%fd1780, %fd1;
	mov.f64 	%fd1787, %fd2;
	mov.f64 	%fd1794, %fd3;
	@%p2 bra 	BB0_5;

	abs.f64 	%fd266, %fd4;
	setp.gtu.f64	%p3, %fd266, 0d7FF0000000000000;
	mov.f64 	%fd1775, %fd1;
	mov.f64 	%fd1780, %fd1775;
	mov.f64 	%fd1782, %fd2;
	mov.f64 	%fd1787, %fd1782;
	mov.f64 	%fd1789, %fd3;
	mov.f64 	%fd1794, %fd1789;
	@%p3 bra 	BB0_5;

	add.f64 	%fd1780, %fd1, %fd5;
	add.f64 	%fd1787, %fd2, %fd4;
	add.f64 	%fd1794, %fd3, 0d3FF0000000000000;

BB0_5:
	mov.f64 	%fd1793, %fd1794;
	mov.f64 	%fd1786, %fd1787;
	mov.f64 	%fd1779, %fd1780;
	add.s32 	%r331, %r331, 1;
	add.s32 	%r5, %r331, %r1;
	setp.lt.s32	%p4, %r5, 6;
	setp.lt.s32	%p5, %r331, 2;
	and.pred  	%p6, %p4, %p5;
	mov.f64 	%fd1778, %fd1779;
	mov.f64 	%fd1785, %fd1786;
	mov.f64 	%fd1792, %fd1793;
	mov.u32 	%r371, %r5;
	@%p6 bra 	BB0_2;

BB0_6:
	setp.lt.f64	%p7, %fd1792, 0d3FF0000000000000;
	mov.f64 	%fd1815, 0dFFF8000000000000;
	@%p7 bra 	BB0_75;

	setp.eq.f64	%p8, %fd1792, 0d3FF0000000000000;
	mov.f64 	%fd1797, 0d3FF0000000000000;
	@%p8 bra 	BB0_38;

	abs.f64 	%fd15, %fd1792;
	setp.gtu.f64	%p9, %fd15, 0d7FF0000000000000;
	@%p9 bra 	BB0_37;
	bra.uni 	BB0_9;

BB0_37:
	add.f64 	%fd1797, %fd1792, 0dBFF0000000000000;
	bra.uni 	BB0_38;

BB0_9:
	setp.eq.f64	%p10, %fd1792, 0d7FF0000000000000;
	mov.f64 	%fd269, 0dBFF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd269;
	}
	@%p10 bra 	BB0_36;
	bra.uni 	BB0_10;

BB0_36:
	setp.gt.s32	%p32, %r6, -1;
	selp.f64	%fd1797, 0d7FF0000000000000, 0d0000000000000000, %p32;
	bra.uni 	BB0_38;

BB0_10:
	and.b32  	%r149, %r6, 2147483647;
	setp.ne.s32	%p11, %r149, 2146435072;
	@%p11 bra 	BB0_12;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r150, %temp}, %fd269;
	}
	setp.eq.s32	%p12, %r150, 0;
	@%p12 bra 	BB0_34;

BB0_12:
	mov.f64 	%fd272, 0d3FE0000000000000;
	mul.rn.f64 	%fd273, %fd272, %fd269;
	cvt.rzi.f64.f64	%fd274, %fd273;
	mov.f64 	%fd275, 0d4000000000000000;
	mul.rn.f64 	%fd276, %fd275, %fd274;
	sub.f64 	%fd277, %fd269, %fd276;
	abs.f64 	%fd16, %fd277;
	setp.eq.f64	%p13, %fd1792, 0d0000000000000000;
	@%p13 bra 	BB0_33;
	bra.uni 	BB0_13;

BB0_33:
	setp.eq.f64	%p29, %fd16, 0d3FF0000000000000;
	rcp.rn.f64 	%fd457, %fd1792;
	mov.f64 	%fd458, 0d0000000000000000;
	rcp.rn.f64 	%fd459, %fd458;
	selp.f64	%fd1797, %fd457, %fd459, %p29;
	bra.uni 	BB0_38;

BB0_13:
	setp.eq.f64	%p14, %fd1792, 0dFFF0000000000000;
	@%p14 bra 	BB0_31;
	bra.uni 	BB0_14;

BB0_31:
	div.rn.f64 	%fd1797, %fd269, %fd1792;
	setp.neu.f64	%p28, %fd16, 0d3FF0000000000000;
	@%p28 bra 	BB0_38;

	mov.b64 	 %rd21, %fd1797;
	xor.b64  	%rd22, %rd21, -9223372036854775808;
	mov.b64 	 %fd1797, %rd22;
	bra.uni 	BB0_38;

BB0_34:
	setp.eq.f64	%p30, %fd1792, 0dBFF0000000000000;
	@%p30 bra 	BB0_38;

	setp.gt.f64	%p31, %fd15, 0d3FF0000000000000;
	mov.f64 	%fd461, 0d0000000000000000;
	rcp.rn.f64 	%fd462, %fd461;
	selp.f64	%fd1797, 0d0000000000000000, %fd462, %p31;
	bra.uni 	BB0_38;

BB0_14:
	setp.geu.f64	%p15, %fd1792, 0d0000000000000000;
	@%p15 bra 	BB0_16;

	cvt.rzi.f64.f64	%fd280, %fd269;
	setp.neu.f64	%p16, %fd280, 0dBFF0000000000000;
	mov.f64 	%fd1797, 0dFFF8000000000000;
	@%p16 bra 	BB0_38;

BB0_16:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r333}, %fd15; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r332, hi}, %fd15; 
	}
	// inline asm
	bfe.u32 	%r334, %r333, 20, 11;
	setp.ne.s32	%p17, %r334, 0;
	@%p17 bra 	BB0_18;

	mov.f64 	%fd285, 0d4350000000000000;
	mul.rn.f64 	%fd284, %fd15, %fd285;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r333}, %fd284; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r332, hi}, %fd284; 
	}
	// inline asm
	bfe.u32 	%r155, %r333, 20, 11;
	add.s32 	%r334, %r155, -54;

BB0_18:
	and.b32  	%r158, %r333, -2146435073;
	or.b32  	%r157, %r158, 1072693248;
	// inline asm
	mov.b64 	%fd1795, {%r332, %r157};
	// inline asm
	add.s32 	%r335, %r334, -1023;
	setp.lt.u32	%p18, %r157, 1073127583;
	@%p18 bra 	BB0_20;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r159, hi}, %fd1795; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r160}, %fd1795; 
	}
	// inline asm
	add.s32 	%r162, %r160, -1048576;
	// inline asm
	mov.b64 	%fd1795, {%r159, %r162};
	// inline asm
	add.s32 	%r335, %r334, -1022;

BB0_20:
	add.f64 	%fd374, %fd1795, 0d3FF0000000000000;
	rcp.rn.f64 	%fd375, %fd374;
	add.f64 	%fd316, %fd1795, 0dBFF0000000000000;
	mul.rn.f64 	%fd376, %fd316, %fd375;
	add.f64 	%fd364, %fd376, %fd376;
	mul.rn.f64 	%fd312, %fd364, %fd364;
	mov.f64 	%fd291, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd293, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd290, %fd291, %fd312, %fd293;
	// inline asm
	mov.f64 	%fd297, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd294, %fd290, %fd312, %fd297;
	// inline asm
	mov.f64 	%fd301, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd298, %fd294, %fd312, %fd301;
	// inline asm
	mov.f64 	%fd305, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd302, %fd298, %fd312, %fd305;
	// inline asm
	mov.f64 	%fd309, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd306, %fd302, %fd312, %fd309;
	// inline asm
	mov.f64 	%fd313, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd310, %fd306, %fd312, %fd313;
	// inline asm
	mul.rn.f64 	%fd377, %fd310, %fd312;
	sub.f64 	%fd378, %fd316, %fd364;
	mul.rn.f64 	%fd317, %fd275, %fd378;
	neg.f64 	%fd315, %fd364;
	// inline asm
	fma.rn.f64 	%fd314, %fd315, %fd316, %fd317;
	// inline asm
	mul.rn.f64 	%fd360, %fd375, %fd314;
	add.f64 	%fd380, %fd377, 0d3FB5555555555555;
	mov.f64 	%fd381, 0d3FB5555555555555;
	sub.f64 	%fd382, %fd381, %fd380;
	add.f64 	%fd383, %fd377, %fd382;
	add.f64 	%fd384, %fd383, 0d0000000000000000;
	add.f64 	%fd385, %fd384, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd327, %fd380, %fd385;
	sub.f64 	%fd386, %fd380, %fd327;
	add.f64 	%fd331, %fd385, %fd386;
	mul.rn.f64 	%fd387, %fd327, %fd364;
	neg.f64 	%fd321, %fd387;
	// inline asm
	fma.rn.f64 	%fd318, %fd327, %fd364, %fd321;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd322, %fd331, %fd360, %fd318;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd326, %fd327, %fd360, %fd322;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd330, %fd331, %fd364, %fd326;
	// inline asm
	add.f64 	%fd343, %fd387, %fd330;
	sub.f64 	%fd388, %fd387, %fd343;
	add.f64 	%fd347, %fd330, %fd388;
	mul.rn.f64 	%fd389, %fd343, %fd364;
	neg.f64 	%fd337, %fd389;
	// inline asm
	fma.rn.f64 	%fd334, %fd343, %fd364, %fd337;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd338, %fd347, %fd360, %fd334;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd342, %fd343, %fd360, %fd338;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd346, %fd347, %fd364, %fd342;
	// inline asm
	add.f64 	%fd359, %fd389, %fd346;
	sub.f64 	%fd390, %fd389, %fd359;
	add.f64 	%fd363, %fd346, %fd390;
	mul.rn.f64 	%fd391, %fd359, %fd364;
	neg.f64 	%fd353, %fd391;
	// inline asm
	fma.rn.f64 	%fd350, %fd359, %fd364, %fd353;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd354, %fd363, %fd360, %fd350;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd358, %fd359, %fd360, %fd354;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd362, %fd363, %fd364, %fd358;
	// inline asm
	add.f64 	%fd392, %fd391, %fd362;
	sub.f64 	%fd393, %fd391, %fd392;
	add.f64 	%fd394, %fd362, %fd393;
	add.f64 	%fd395, %fd364, %fd392;
	sub.f64 	%fd396, %fd364, %fd395;
	add.f64 	%fd397, %fd392, %fd396;
	add.f64 	%fd398, %fd394, %fd397;
	add.f64 	%fd399, %fd360, %fd398;
	add.f64 	%fd400, %fd395, %fd399;
	sub.f64 	%fd401, %fd395, %fd400;
	add.f64 	%fd402, %fd399, %fd401;
	cvt.rn.f64.s32	%fd403, %r335;
	mov.f64 	%fd404, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd405, %fd403, %fd404;
	mov.f64 	%fd406, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd407, %fd403, %fd406;
	add.f64 	%fd408, %fd405, %fd400;
	sub.f64 	%fd409, %fd405, %fd408;
	add.f64 	%fd410, %fd400, %fd409;
	add.f64 	%fd411, %fd402, %fd410;
	add.f64 	%fd412, %fd407, %fd411;
	add.f64 	%fd367, %fd408, %fd412;
	sub.f64 	%fd413, %fd408, %fd367;
	add.f64 	%fd371, %fd412, %fd413;
	mul.rn.f64 	%fd414, %fd367, %fd269;
	neg.f64 	%fd369, %fd414;
	// inline asm
	fma.rn.f64 	%fd366, %fd367, %fd269, %fd369;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd370, %fd371, %fd269, %fd366;
	// inline asm
	add.f64 	%fd20, %fd414, %fd370;
	sub.f64 	%fd415, %fd414, %fd20;
	add.f64 	%fd21, %fd370, %fd415;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r19}, %fd20;
	}
	mov.b32 	 %f1, %r19;
	abs.f32 	%f2, %f1;
	setp.lt.f32	%p19, %f2, 0f40874911;
	@%p19 bra 	BB0_22;
	bra.uni 	BB0_21;

BB0_22:
	mov.f64 	%fd419, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd420, %fd20, %fd419;
	mov.f64 	%fd421, 0d4338000000000000;
	add.rn.f64 	%fd422, %fd420, %fd421;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd422;
	}
	mov.f64 	%fd423, 0dC338000000000000;
	add.rn.f64 	%fd424, %fd422, %fd423;
	mov.f64 	%fd425, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd426, %fd424, %fd425, %fd20;
	mov.f64 	%fd427, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd428, %fd424, %fd427, %fd426;
	mov.f64 	%fd429, 0d3E928AF3FCA213EA;
	mov.f64 	%fd430, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd431, %fd430, %fd428, %fd429;
	mov.f64 	%fd432, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd433, %fd431, %fd428, %fd432;
	mov.f64 	%fd434, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd435, %fd433, %fd428, %fd434;
	mov.f64 	%fd436, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd437, %fd435, %fd428, %fd436;
	mov.f64 	%fd438, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd439, %fd437, %fd428, %fd438;
	mov.f64 	%fd440, 0d3F81111111122322;
	fma.rn.f64 	%fd441, %fd439, %fd428, %fd440;
	mov.f64 	%fd442, 0d3FA55555555502A1;
	fma.rn.f64 	%fd443, %fd441, %fd428, %fd442;
	mov.f64 	%fd444, 0d3FC5555555555511;
	fma.rn.f64 	%fd445, %fd443, %fd428, %fd444;
	mov.f64 	%fd446, 0d3FE000000000000B;
	fma.rn.f64 	%fd447, %fd445, %fd428, %fd446;
	mov.f64 	%fd448, 0d3FF0000000000000;
	fma.rn.f64 	%fd449, %fd447, %fd428, %fd448;
	fma.rn.f64 	%fd1796, %fd449, %fd428, %fd448;
	abs.s32 	%r163, %r20;
	setp.lt.s32	%p22, %r163, 1023;
	@%p22 bra 	BB0_24;
	bra.uni 	BB0_23;

BB0_24:
	shl.b32 	%r169, %r20, 20;
	add.s32 	%r336, %r169, 1072693248;
	bra.uni 	BB0_25;

BB0_21:
	setp.lt.s32	%p20, %r19, 0;
	selp.f64	%fd416, 0d0000000000000000, 0d7FF0000000000000, %p20;
	abs.f64 	%fd417, %fd20;
	setp.gtu.f64	%p21, %fd417, 0d7FF0000000000000;
	add.f64 	%fd418, %fd20, %fd20;
	selp.f64	%fd1797, %fd418, %fd416, %p21;
	bra.uni 	BB0_26;

BB0_23:
	add.s32 	%r164, %r20, 2046;
	shl.b32 	%r165, %r164, 19;
	and.b32  	%r166, %r165, -1048576;
	shl.b32 	%r167, %r164, 20;
	sub.s32 	%r336, %r167, %r166;
	mov.u32 	%r168, 0;
	mov.b64 	%fd450, {%r168, %r166};
	mul.f64 	%fd1796, %fd1796, %fd450;

BB0_25:
	mov.u32 	%r170, 0;
	mov.b64 	%fd451, {%r170, %r336};
	mul.f64 	%fd1797, %fd1796, %fd451;

BB0_26:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r171}, %fd1797;
	}
	and.b32  	%r172, %r171, 2147483647;
	setp.ne.s32	%p23, %r172, 2146435072;
	@%p23 bra 	BB0_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r173, %temp}, %fd1797;
	}
	setp.eq.s32	%p24, %r173, 0;
	@%p24 bra 	BB0_29;

BB0_28:
	// inline asm
	fma.rn.f64 	%fd1797, %fd1797, %fd21, %fd1797;
	// inline asm

BB0_29:
	setp.neu.f64	%p25, %fd16, 0d3FF0000000000000;
	or.pred  	%p27, %p15, %p25;
	@%p27 bra 	BB0_38;

	mov.b64 	 %rd19, %fd1797;
	xor.b64  	%rd20, %rd19, -9223372036854775808;
	mov.b64 	 %fd1797, %rd20;

BB0_38:
	mul.f64 	%fd38, %fd1778, %fd1797;
	mul.f64 	%fd39, %fd1785, %fd1797;
	mov.f64 	%fd1809, 0d0000000000000000;
	mov.f64 	%fd1802, %fd1809;
	mov.f64 	%fd1810, %fd1809;
	mov.f64 	%fd1803, %fd1809;
	mov.u32 	%r337, 0;
	@%p1 bra 	BB0_44;

	mov.u32 	%r370, %r1;

BB0_40:
	mov.u32 	%r24, %r370;
	mov.f64 	%fd1805, %fd1810;
	mov.f64 	%fd41, %fd1805;
	mov.f64 	%fd1798, %fd1803;
	mov.f64 	%fd40, %fd1798;
	mul.wide.s32 	%rd23, %r24, 8;
	add.s64 	%rd24, %rd15, %rd23;
	add.s64 	%rd25, %rd14, %rd23;
	ld.global.f64 	%fd42, [%rd25];
	ld.global.f64 	%fd43, [%rd24];
	abs.f64 	%fd467, %fd43;
	setp.gtu.f64	%p34, %fd467, 0d7FF0000000000000;
	mov.f64 	%fd1804, %fd40;
	mov.f64 	%fd1811, %fd41;
	@%p34 bra 	BB0_43;

	abs.f64 	%fd468, %fd42;
	setp.gtu.f64	%p35, %fd468, 0d7FF0000000000000;
	mov.f64 	%fd1799, %fd40;
	mov.f64 	%fd1804, %fd1799;
	mov.f64 	%fd1806, %fd41;
	mov.f64 	%fd1811, %fd1806;
	@%p35 bra 	BB0_43;

	sub.f64 	%fd469, %fd43, %fd38;
	sub.f64 	%fd470, %fd42, %fd39;
	fma.rn.f64 	%fd1804, %fd469, %fd470, %fd40;
	fma.rn.f64 	%fd1811, %fd469, %fd469, %fd41;

BB0_43:
	mov.f64 	%fd1810, %fd1811;
	mov.f64 	%fd1803, %fd1804;
	add.s32 	%r337, %r337, 1;
	add.s32 	%r370, %r337, %r1;
	setp.lt.s32	%p36, %r370, 6;
	setp.lt.s32	%p37, %r337, 2;
	and.pred  	%p38, %p36, %p37;
	mov.f64 	%fd1802, %fd1803;
	mov.f64 	%fd1809, %fd1810;
	@%p38 bra 	BB0_40;

BB0_44:
	mov.f64 	%fd1815, 0dFFF8000000000000;
	setp.eq.f64	%p39, %fd1809, 0d0000000000000000;
	@%p39 bra 	BB0_75;

	setp.eq.f64	%p40, %fd1809, 0d3FF0000000000000;
	mov.f64 	%fd1814, 0d3FF0000000000000;
	@%p40 bra 	BB0_74;

	abs.f64 	%fd50, %fd1809;
	setp.gtu.f64	%p41, %fd50, 0d7FF0000000000000;
	@%p41 bra 	BB0_73;
	bra.uni 	BB0_47;

BB0_73:
	add.f64 	%fd1814, %fd1809, 0dBFF0000000000000;
	bra.uni 	BB0_74;

BB0_47:
	setp.eq.f64	%p42, %fd1809, 0d7FF0000000000000;
	mov.f64 	%fd473, 0dBFF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd473;
	}
	@%p42 bra 	BB0_72;
	bra.uni 	BB0_48;

BB0_72:
	setp.gt.s32	%p62, %r28, -1;
	selp.f64	%fd1814, 0d7FF0000000000000, 0d0000000000000000, %p62;

BB0_74:
	fma.rn.f64 	%fd1815, %fd1802, %fd1814, 0d0000000000000000;

BB0_75:
	mov.f64 	%fd669, 0d0000000000000000;
	mov.f64 	%fd1824, %fd669;
	mov.f64 	%fd1820, %fd669;
	mov.f64 	%fd1846, %fd669;
	mov.f64 	%fd1825, %fd669;
	mov.f64 	%fd1822, %fd669;
	mov.u32 	%r343, 0;
	mov.f64 	%fd1845, %fd669;
	@%p1 bra 	BB0_81;

	mov.u32 	%r369, %r1;

BB0_77:
	mov.u32 	%r46, %r369;
	mov.f64 	%fd1819, %fd1822;
	mov.f64 	%fd1821, %fd1819;
	mul.wide.s32 	%rd30, %r46, 8;
	add.s64 	%rd31, %rd12, %rd30;
	add.s64 	%rd32, %rd13, %rd30;
	ld.global.f64 	%fd1817, [%rd32];
	ld.global.f64 	%fd1816, [%rd31];
	abs.f64 	%fd670, %fd1816;
	setp.gtu.f64	%p64, %fd670, 0d7FF0000000000000;
	@%p64 bra 	BB0_79;

	abs.f64 	%fd671, %fd1817;
	setp.le.f64	%p65, %fd671, 0d7FF0000000000000;
	@%p65 bra 	BB0_80;

BB0_79:
	add.f64 	%fd1821, %fd1821, 0dBFF0000000000000;
	mov.f64 	%fd1817, 0d0000000000000000;
	mov.f64 	%fd1816, %fd1817;

BB0_80:
	add.f64 	%fd1825, %fd1825, %fd1816;
	add.f64 	%fd1846, %fd1846, %fd1817;
	add.f64 	%fd1822, %fd1821, 0d3FF0000000000000;
	add.s32 	%r343, %r343, 1;
	add.s32 	%r369, %r343, %r1;
	setp.lt.s32	%p66, %r369, 6;
	setp.lt.s32	%p67, %r343, 2;
	and.pred  	%p68, %p66, %p67;
	mov.f64 	%fd1820, %fd1822;
	mov.f64 	%fd1824, %fd1825;
	mov.f64 	%fd1840, %fd1846;
	mov.f64 	%fd1845, %fd1840;
	@%p68 bra 	BB0_77;

BB0_81:
	mov.f64 	%fd88, %fd1845;
	div.rn.f64 	%fd89, %fd1824, %fd1820;
	div.rn.f64 	%fd90, %fd88, %fd1820;
	mov.f64 	%fd1838, %fd669;
	mov.f64 	%fd1835, %fd669;
	mov.f64 	%fd1844, %fd669;
	mov.f64 	%fd1839, %fd669;
	mov.f64 	%fd1836, %fd669;
	mov.u32 	%r344, 0;
	mov.f64 	%fd1843, %fd669;
	@%p1 bra 	BB0_149;

	mov.u32 	%r368, %r1;

BB0_83:
	mov.u32 	%r50, %r368;
	mul.wide.s32 	%rd33, %r50, 8;
	add.s64 	%rd34, %rd12, %rd33;
	add.s64 	%rd35, %rd13, %rd33;
	ld.global.f64 	%fd1827, [%rd35];
	ld.global.f64 	%fd1826, [%rd34];
	abs.f64 	%fd680, %fd1826;
	setp.gtu.f64	%p70, %fd680, 0d7FF0000000000000;
	@%p70 bra 	BB0_85;

	abs.f64 	%fd681, %fd1827;
	setp.le.f64	%p71, %fd681, 0d7FF0000000000000;
	@%p71 bra 	BB0_86;

BB0_85:
	mov.f64 	%fd1827, 0d0000000000000000;
	mov.f64 	%fd1826, %fd1827;

BB0_86:
	sub.f64 	%fd98, %fd1827, %fd90;
	sub.f64 	%fd99, %fd1826, %fd89;
	fma.rn.f64 	%fd1844, %fd99, %fd98, %fd1844;
	setp.eq.f64	%p72, %fd99, 0d3FF0000000000000;
	mov.f64 	%fd1830, 0d3FF0000000000000;
	@%p72 bra 	BB0_117;

	abs.f64 	%fd101, %fd99;
	setp.gtu.f64	%p73, %fd101, 0d7FF0000000000000;
	@%p73 bra 	BB0_116;
	bra.uni 	BB0_88;

BB0_116:
	add.f64 	%fd1830, %fd99, 0d4000000000000000;
	bra.uni 	BB0_117;

BB0_88:
	setp.eq.f64	%p74, %fd99, 0d7FF0000000000000;
	mov.f64 	%fd685, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd685;
	}
	@%p74 bra 	BB0_115;
	bra.uni 	BB0_89;

BB0_115:
	setp.gt.s32	%p96, %r52, -1;
	selp.f64	%fd1830, 0d7FF0000000000000, 0d0000000000000000, %p96;
	bra.uni 	BB0_117;

BB0_89:
	and.b32  	%r202, %r52, 2147483647;
	setp.ne.s32	%p75, %r202, 2146435072;
	@%p75 bra 	BB0_91;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r203, %temp}, %fd685;
	}
	setp.eq.s32	%p76, %r203, 0;
	@%p76 bra 	BB0_113;
	bra.uni 	BB0_91;

BB0_113:
	setp.eq.f64	%p94, %fd99, 0dBFF0000000000000;
	@%p94 bra 	BB0_117;

	setp.gt.f64	%p95, %fd101, 0d3FF0000000000000;
	selp.f64	%fd1830, 0d7FF0000000000000, 0d0000000000000000, %p95;
	bra.uni 	BB0_117;

BB0_91:
	mov.f64 	%fd688, 0d3FE0000000000000;
	mul.rn.f64 	%fd689, %fd688, %fd685;
	cvt.rzi.f64.f64	%fd690, %fd689;
	mul.rn.f64 	%fd691, %fd685, %fd690;
	sub.f64 	%fd692, %fd685, %fd691;
	abs.f64 	%fd102, %fd692;
	setp.eq.f64	%p77, %fd99, 0d0000000000000000;
	@%p77 bra 	BB0_112;
	bra.uni 	BB0_92;

BB0_112:
	setp.eq.f64	%p93, %fd102, 0d3FF0000000000000;
	selp.f64	%fd1830, %fd99, 0d0000000000000000, %p93;
	bra.uni 	BB0_117;

BB0_92:
	setp.eq.f64	%p78, %fd99, 0dFFF0000000000000;
	@%p78 bra 	BB0_110;
	bra.uni 	BB0_93;

BB0_110:
	neg.f64 	%fd1830, %fd99;
	setp.neu.f64	%p92, %fd102, 0d3FF0000000000000;
	@%p92 bra 	BB0_117;

	mov.b64 	 %rd38, %fd1830;
	xor.b64  	%rd39, %rd38, -9223372036854775808;
	mov.b64 	 %fd1830, %rd39;
	bra.uni 	BB0_117;

BB0_93:
	setp.geu.f64	%p79, %fd99, 0d0000000000000000;
	@%p79 bra 	BB0_95;

	cvt.rzi.f64.f64	%fd695, %fd685;
	setp.neu.f64	%p80, %fd695, 0d4000000000000000;
	mov.f64 	%fd1830, 0dFFF8000000000000;
	@%p80 bra 	BB0_117;

BB0_95:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r346}, %fd101; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r345, hi}, %fd101; 
	}
	// inline asm
	bfe.u32 	%r347, %r346, 20, 11;
	setp.ne.s32	%p81, %r347, 0;
	@%p81 bra 	BB0_97;

	mov.f64 	%fd700, 0d4350000000000000;
	mul.rn.f64 	%fd699, %fd101, %fd700;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r346}, %fd699; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r345, hi}, %fd699; 
	}
	// inline asm
	bfe.u32 	%r208, %r346, 20, 11;
	add.s32 	%r347, %r208, -54;

BB0_97:
	and.b32  	%r211, %r346, -2146435073;
	or.b32  	%r210, %r211, 1072693248;
	// inline asm
	mov.b64 	%fd1828, {%r345, %r210};
	// inline asm
	add.s32 	%r348, %r347, -1023;
	setp.lt.u32	%p82, %r210, 1073127583;
	@%p82 bra 	BB0_99;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r212, hi}, %fd1828; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r213}, %fd1828; 
	}
	// inline asm
	add.s32 	%r215, %r213, -1048576;
	// inline asm
	mov.b64 	%fd1828, {%r212, %r215};
	// inline asm
	add.s32 	%r348, %r347, -1022;

BB0_99:
	add.f64 	%fd789, %fd1828, 0d3FF0000000000000;
	rcp.rn.f64 	%fd790, %fd789;
	add.f64 	%fd731, %fd1828, 0dBFF0000000000000;
	mul.rn.f64 	%fd791, %fd731, %fd790;
	add.f64 	%fd779, %fd791, %fd791;
	mul.rn.f64 	%fd727, %fd779, %fd779;
	mov.f64 	%fd706, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd708, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd705, %fd706, %fd727, %fd708;
	// inline asm
	mov.f64 	%fd712, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd709, %fd705, %fd727, %fd712;
	// inline asm
	mov.f64 	%fd716, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd713, %fd709, %fd727, %fd716;
	// inline asm
	mov.f64 	%fd720, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd717, %fd713, %fd727, %fd720;
	// inline asm
	mov.f64 	%fd724, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd721, %fd717, %fd727, %fd724;
	// inline asm
	mov.f64 	%fd728, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd725, %fd721, %fd727, %fd728;
	// inline asm
	mul.rn.f64 	%fd792, %fd725, %fd727;
	sub.f64 	%fd793, %fd731, %fd779;
	mul.rn.f64 	%fd732, %fd685, %fd793;
	neg.f64 	%fd730, %fd779;
	// inline asm
	fma.rn.f64 	%fd729, %fd730, %fd731, %fd732;
	// inline asm
	mul.rn.f64 	%fd775, %fd790, %fd729;
	add.f64 	%fd794, %fd792, 0d3FB5555555555555;
	mov.f64 	%fd795, 0d3FB5555555555555;
	sub.f64 	%fd796, %fd795, %fd794;
	add.f64 	%fd797, %fd792, %fd796;
	add.f64 	%fd798, %fd797, 0d0000000000000000;
	add.f64 	%fd799, %fd798, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd742, %fd794, %fd799;
	sub.f64 	%fd800, %fd794, %fd742;
	add.f64 	%fd746, %fd799, %fd800;
	mul.rn.f64 	%fd801, %fd742, %fd779;
	neg.f64 	%fd736, %fd801;
	// inline asm
	fma.rn.f64 	%fd733, %fd742, %fd779, %fd736;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd737, %fd746, %fd775, %fd733;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd741, %fd742, %fd775, %fd737;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd745, %fd746, %fd779, %fd741;
	// inline asm
	add.f64 	%fd758, %fd801, %fd745;
	sub.f64 	%fd802, %fd801, %fd758;
	add.f64 	%fd762, %fd745, %fd802;
	mul.rn.f64 	%fd803, %fd758, %fd779;
	neg.f64 	%fd752, %fd803;
	// inline asm
	fma.rn.f64 	%fd749, %fd758, %fd779, %fd752;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd753, %fd762, %fd775, %fd749;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd757, %fd758, %fd775, %fd753;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd761, %fd762, %fd779, %fd757;
	// inline asm
	add.f64 	%fd774, %fd803, %fd761;
	sub.f64 	%fd804, %fd803, %fd774;
	add.f64 	%fd778, %fd761, %fd804;
	mul.rn.f64 	%fd805, %fd774, %fd779;
	neg.f64 	%fd768, %fd805;
	// inline asm
	fma.rn.f64 	%fd765, %fd774, %fd779, %fd768;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd769, %fd778, %fd775, %fd765;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd773, %fd774, %fd775, %fd769;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd777, %fd778, %fd779, %fd773;
	// inline asm
	add.f64 	%fd806, %fd805, %fd777;
	sub.f64 	%fd807, %fd805, %fd806;
	add.f64 	%fd808, %fd777, %fd807;
	add.f64 	%fd809, %fd779, %fd806;
	sub.f64 	%fd810, %fd779, %fd809;
	add.f64 	%fd811, %fd806, %fd810;
	add.f64 	%fd812, %fd808, %fd811;
	add.f64 	%fd813, %fd775, %fd812;
	add.f64 	%fd814, %fd809, %fd813;
	sub.f64 	%fd815, %fd809, %fd814;
	add.f64 	%fd816, %fd813, %fd815;
	cvt.rn.f64.s32	%fd817, %r348;
	mov.f64 	%fd818, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd819, %fd817, %fd818;
	mov.f64 	%fd820, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd821, %fd817, %fd820;
	add.f64 	%fd822, %fd819, %fd814;
	sub.f64 	%fd823, %fd819, %fd822;
	add.f64 	%fd824, %fd814, %fd823;
	add.f64 	%fd825, %fd816, %fd824;
	add.f64 	%fd826, %fd821, %fd825;
	add.f64 	%fd782, %fd822, %fd826;
	sub.f64 	%fd827, %fd822, %fd782;
	add.f64 	%fd786, %fd826, %fd827;
	mul.rn.f64 	%fd828, %fd782, %fd685;
	neg.f64 	%fd784, %fd828;
	// inline asm
	fma.rn.f64 	%fd781, %fd782, %fd685, %fd784;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd785, %fd786, %fd685, %fd781;
	// inline asm
	add.f64 	%fd106, %fd828, %fd785;
	sub.f64 	%fd829, %fd828, %fd106;
	add.f64 	%fd107, %fd785, %fd829;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd106;
	}
	mov.b32 	 %f5, %r65;
	abs.f32 	%f6, %f5;
	setp.lt.f32	%p83, %f6, 0f40874911;
	@%p83 bra 	BB0_101;
	bra.uni 	BB0_100;

BB0_101:
	mov.f64 	%fd833, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd834, %fd106, %fd833;
	mov.f64 	%fd835, 0d4338000000000000;
	add.rn.f64 	%fd836, %fd834, %fd835;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r66, %temp}, %fd836;
	}
	mov.f64 	%fd837, 0dC338000000000000;
	add.rn.f64 	%fd838, %fd836, %fd837;
	mov.f64 	%fd839, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd840, %fd838, %fd839, %fd106;
	mov.f64 	%fd841, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd842, %fd838, %fd841, %fd840;
	mov.f64 	%fd843, 0d3E928AF3FCA213EA;
	mov.f64 	%fd844, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd845, %fd844, %fd842, %fd843;
	mov.f64 	%fd846, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd847, %fd845, %fd842, %fd846;
	mov.f64 	%fd848, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd849, %fd847, %fd842, %fd848;
	mov.f64 	%fd850, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd851, %fd849, %fd842, %fd850;
	mov.f64 	%fd852, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd853, %fd851, %fd842, %fd852;
	mov.f64 	%fd854, 0d3F81111111122322;
	fma.rn.f64 	%fd855, %fd853, %fd842, %fd854;
	mov.f64 	%fd856, 0d3FA55555555502A1;
	fma.rn.f64 	%fd857, %fd855, %fd842, %fd856;
	mov.f64 	%fd858, 0d3FC5555555555511;
	fma.rn.f64 	%fd859, %fd857, %fd842, %fd858;
	mov.f64 	%fd860, 0d3FE000000000000B;
	fma.rn.f64 	%fd861, %fd859, %fd842, %fd860;
	mov.f64 	%fd862, 0d3FF0000000000000;
	fma.rn.f64 	%fd863, %fd861, %fd842, %fd862;
	fma.rn.f64 	%fd1829, %fd863, %fd842, %fd862;
	abs.s32 	%r216, %r66;
	setp.lt.s32	%p86, %r216, 1023;
	@%p86 bra 	BB0_103;
	bra.uni 	BB0_102;

BB0_103:
	shl.b32 	%r222, %r66, 20;
	add.s32 	%r349, %r222, 1072693248;
	bra.uni 	BB0_104;

BB0_100:
	setp.lt.s32	%p84, %r65, 0;
	selp.f64	%fd830, 0d0000000000000000, 0d7FF0000000000000, %p84;
	abs.f64 	%fd831, %fd106;
	setp.gtu.f64	%p85, %fd831, 0d7FF0000000000000;
	add.f64 	%fd832, %fd106, %fd106;
	selp.f64	%fd1830, %fd832, %fd830, %p85;
	bra.uni 	BB0_105;

BB0_102:
	add.s32 	%r217, %r66, 2046;
	shl.b32 	%r218, %r217, 19;
	and.b32  	%r219, %r218, -1048576;
	shl.b32 	%r220, %r217, 20;
	sub.s32 	%r349, %r220, %r219;
	mov.u32 	%r221, 0;
	mov.b64 	%fd864, {%r221, %r219};
	mul.f64 	%fd1829, %fd1829, %fd864;

BB0_104:
	mov.u32 	%r223, 0;
	mov.b64 	%fd865, {%r223, %r349};
	mul.f64 	%fd1830, %fd1829, %fd865;

BB0_105:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r224}, %fd1830;
	}
	and.b32  	%r225, %r224, 2147483647;
	setp.ne.s32	%p87, %r225, 2146435072;
	@%p87 bra 	BB0_107;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r226, %temp}, %fd1830;
	}
	setp.eq.s32	%p88, %r226, 0;
	@%p88 bra 	BB0_108;

BB0_107:
	// inline asm
	fma.rn.f64 	%fd1830, %fd1830, %fd107, %fd1830;
	// inline asm

BB0_108:
	setp.neu.f64	%p89, %fd102, 0d3FF0000000000000;
	or.pred  	%p91, %p79, %p89;
	@%p91 bra 	BB0_117;

	mov.b64 	 %rd36, %fd1830;
	xor.b64  	%rd37, %rd36, -9223372036854775808;
	mov.b64 	 %fd1830, %rd37;

BB0_117:
	mov.f64 	%fd1833, 0d3FF0000000000000;
	add.f64 	%fd1836, %fd1836, %fd1830;
	setp.eq.f64	%p97, %fd98, 0d3FF0000000000000;
	@%p97 bra 	BB0_148;

	abs.f64 	%fd125, %fd98;
	setp.gtu.f64	%p98, %fd125, 0d7FF0000000000000;
	@%p98 bra 	BB0_147;
	bra.uni 	BB0_119;

BB0_147:
	add.f64 	%fd1833, %fd98, 0d4000000000000000;
	bra.uni 	BB0_148;

BB0_119:
	setp.eq.f64	%p99, %fd98, 0d7FF0000000000000;
	mov.f64 	%fd872, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd872;
	}
	@%p99 bra 	BB0_146;
	bra.uni 	BB0_120;

BB0_146:
	setp.gt.s32	%p121, %r70, -1;
	selp.f64	%fd1833, 0d7FF0000000000000, 0d0000000000000000, %p121;
	bra.uni 	BB0_148;

BB0_120:
	and.b32  	%r227, %r70, 2147483647;
	setp.ne.s32	%p100, %r227, 2146435072;
	@%p100 bra 	BB0_122;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r228, %temp}, %fd872;
	}
	setp.eq.s32	%p101, %r228, 0;
	@%p101 bra 	BB0_144;
	bra.uni 	BB0_122;

BB0_144:
	mov.f64 	%fd1833, 0d3FF0000000000000;
	setp.eq.f64	%p119, %fd98, 0dBFF0000000000000;
	@%p119 bra 	BB0_148;

	setp.gt.f64	%p120, %fd125, 0d3FF0000000000000;
	selp.f64	%fd1833, 0d7FF0000000000000, 0d0000000000000000, %p120;
	bra.uni 	BB0_148;

BB0_122:
	mov.f64 	%fd875, 0d3FE0000000000000;
	mul.rn.f64 	%fd876, %fd875, %fd872;
	cvt.rzi.f64.f64	%fd877, %fd876;
	mul.rn.f64 	%fd878, %fd872, %fd877;
	sub.f64 	%fd879, %fd872, %fd878;
	abs.f64 	%fd126, %fd879;
	setp.eq.f64	%p102, %fd98, 0d0000000000000000;
	@%p102 bra 	BB0_143;
	bra.uni 	BB0_123;

BB0_143:
	setp.eq.f64	%p118, %fd126, 0d3FF0000000000000;
	selp.f64	%fd1833, %fd98, 0d0000000000000000, %p118;
	bra.uni 	BB0_148;

BB0_123:
	setp.eq.f64	%p103, %fd98, 0dFFF0000000000000;
	@%p103 bra 	BB0_141;
	bra.uni 	BB0_124;

BB0_141:
	neg.f64 	%fd1833, %fd98;
	setp.neu.f64	%p117, %fd126, 0d3FF0000000000000;
	@%p117 bra 	BB0_148;

	mov.b64 	 %rd42, %fd1833;
	xor.b64  	%rd43, %rd42, -9223372036854775808;
	mov.b64 	 %fd1833, %rd43;
	bra.uni 	BB0_148;

BB0_124:
	setp.geu.f64	%p104, %fd98, 0d0000000000000000;
	@%p104 bra 	BB0_126;

	cvt.rzi.f64.f64	%fd882, %fd872;
	setp.neu.f64	%p105, %fd882, 0d4000000000000000;
	mov.f64 	%fd1833, 0dFFF8000000000000;
	@%p105 bra 	BB0_148;

BB0_126:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r351}, %fd125; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r350, hi}, %fd125; 
	}
	// inline asm
	bfe.u32 	%r352, %r351, 20, 11;
	setp.ne.s32	%p106, %r352, 0;
	@%p106 bra 	BB0_128;

	mov.f64 	%fd887, 0d4350000000000000;
	mul.rn.f64 	%fd886, %fd125, %fd887;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r351}, %fd886; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r350, hi}, %fd886; 
	}
	// inline asm
	bfe.u32 	%r233, %r351, 20, 11;
	add.s32 	%r352, %r233, -54;

BB0_128:
	add.s32 	%r353, %r352, -1023;
	and.b32  	%r236, %r351, -2146435073;
	or.b32  	%r235, %r236, 1072693248;
	// inline asm
	mov.b64 	%fd1831, {%r350, %r235};
	// inline asm
	setp.lt.u32	%p107, %r235, 1073127583;
	@%p107 bra 	BB0_130;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r237, hi}, %fd1831; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r238}, %fd1831; 
	}
	// inline asm
	add.s32 	%r240, %r238, -1048576;
	// inline asm
	mov.b64 	%fd1831, {%r237, %r240};
	// inline asm
	add.s32 	%r353, %r352, -1022;

BB0_130:
	add.f64 	%fd976, %fd1831, 0d3FF0000000000000;
	rcp.rn.f64 	%fd977, %fd976;
	add.f64 	%fd918, %fd1831, 0dBFF0000000000000;
	mul.rn.f64 	%fd978, %fd918, %fd977;
	add.f64 	%fd966, %fd978, %fd978;
	mul.rn.f64 	%fd914, %fd966, %fd966;
	mov.f64 	%fd893, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd895, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd892, %fd893, %fd914, %fd895;
	// inline asm
	mov.f64 	%fd899, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd896, %fd892, %fd914, %fd899;
	// inline asm
	mov.f64 	%fd903, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd900, %fd896, %fd914, %fd903;
	// inline asm
	mov.f64 	%fd907, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd904, %fd900, %fd914, %fd907;
	// inline asm
	mov.f64 	%fd911, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd908, %fd904, %fd914, %fd911;
	// inline asm
	mov.f64 	%fd915, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd912, %fd908, %fd914, %fd915;
	// inline asm
	mul.rn.f64 	%fd979, %fd912, %fd914;
	sub.f64 	%fd980, %fd918, %fd966;
	mul.rn.f64 	%fd919, %fd872, %fd980;
	neg.f64 	%fd917, %fd966;
	// inline asm
	fma.rn.f64 	%fd916, %fd917, %fd918, %fd919;
	// inline asm
	mul.rn.f64 	%fd962, %fd977, %fd916;
	add.f64 	%fd981, %fd979, 0d3FB5555555555555;
	mov.f64 	%fd982, 0d3FB5555555555555;
	sub.f64 	%fd983, %fd982, %fd981;
	add.f64 	%fd984, %fd979, %fd983;
	add.f64 	%fd985, %fd984, 0d0000000000000000;
	add.f64 	%fd986, %fd985, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd929, %fd981, %fd986;
	sub.f64 	%fd987, %fd981, %fd929;
	add.f64 	%fd933, %fd986, %fd987;
	mul.rn.f64 	%fd988, %fd929, %fd966;
	neg.f64 	%fd923, %fd988;
	// inline asm
	fma.rn.f64 	%fd920, %fd929, %fd966, %fd923;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd924, %fd933, %fd962, %fd920;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd928, %fd929, %fd962, %fd924;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd932, %fd933, %fd966, %fd928;
	// inline asm
	add.f64 	%fd945, %fd988, %fd932;
	sub.f64 	%fd989, %fd988, %fd945;
	add.f64 	%fd949, %fd932, %fd989;
	mul.rn.f64 	%fd990, %fd945, %fd966;
	neg.f64 	%fd939, %fd990;
	// inline asm
	fma.rn.f64 	%fd936, %fd945, %fd966, %fd939;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd940, %fd949, %fd962, %fd936;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd944, %fd945, %fd962, %fd940;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd948, %fd949, %fd966, %fd944;
	// inline asm
	add.f64 	%fd961, %fd990, %fd948;
	sub.f64 	%fd991, %fd990, %fd961;
	add.f64 	%fd965, %fd948, %fd991;
	mul.rn.f64 	%fd992, %fd961, %fd966;
	neg.f64 	%fd955, %fd992;
	// inline asm
	fma.rn.f64 	%fd952, %fd961, %fd966, %fd955;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd956, %fd965, %fd962, %fd952;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd960, %fd961, %fd962, %fd956;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd964, %fd965, %fd966, %fd960;
	// inline asm
	add.f64 	%fd993, %fd992, %fd964;
	sub.f64 	%fd994, %fd992, %fd993;
	add.f64 	%fd995, %fd964, %fd994;
	add.f64 	%fd996, %fd966, %fd993;
	sub.f64 	%fd997, %fd966, %fd996;
	add.f64 	%fd998, %fd993, %fd997;
	add.f64 	%fd999, %fd995, %fd998;
	add.f64 	%fd1000, %fd962, %fd999;
	add.f64 	%fd1001, %fd996, %fd1000;
	sub.f64 	%fd1002, %fd996, %fd1001;
	add.f64 	%fd1003, %fd1000, %fd1002;
	cvt.rn.f64.s32	%fd1004, %r353;
	mov.f64 	%fd1005, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd1006, %fd1004, %fd1005;
	mov.f64 	%fd1007, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd1008, %fd1004, %fd1007;
	add.f64 	%fd1009, %fd1006, %fd1001;
	sub.f64 	%fd1010, %fd1006, %fd1009;
	add.f64 	%fd1011, %fd1001, %fd1010;
	add.f64 	%fd1012, %fd1003, %fd1011;
	add.f64 	%fd1013, %fd1008, %fd1012;
	add.f64 	%fd969, %fd1009, %fd1013;
	sub.f64 	%fd1014, %fd1009, %fd969;
	add.f64 	%fd973, %fd1013, %fd1014;
	mul.rn.f64 	%fd1015, %fd969, %fd872;
	neg.f64 	%fd971, %fd1015;
	// inline asm
	fma.rn.f64 	%fd968, %fd969, %fd872, %fd971;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd972, %fd973, %fd872, %fd968;
	// inline asm
	add.f64 	%fd130, %fd1015, %fd972;
	sub.f64 	%fd1016, %fd1015, %fd130;
	add.f64 	%fd131, %fd972, %fd1016;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd130;
	}
	mov.b32 	 %f7, %r83;
	abs.f32 	%f8, %f7;
	setp.lt.f32	%p108, %f8, 0f40874911;
	@%p108 bra 	BB0_132;
	bra.uni 	BB0_131;

BB0_132:
	mov.f64 	%fd1020, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1021, %fd130, %fd1020;
	mov.f64 	%fd1022, 0d4338000000000000;
	add.rn.f64 	%fd1023, %fd1021, %fd1022;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r84, %temp}, %fd1023;
	}
	mov.f64 	%fd1024, 0dC338000000000000;
	add.rn.f64 	%fd1025, %fd1023, %fd1024;
	mov.f64 	%fd1026, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1027, %fd1025, %fd1026, %fd130;
	mov.f64 	%fd1028, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd1029, %fd1025, %fd1028, %fd1027;
	mov.f64 	%fd1030, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1031, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1032, %fd1031, %fd1029, %fd1030;
	mov.f64 	%fd1033, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1034, %fd1032, %fd1029, %fd1033;
	mov.f64 	%fd1035, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1036, %fd1034, %fd1029, %fd1035;
	mov.f64 	%fd1037, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1038, %fd1036, %fd1029, %fd1037;
	mov.f64 	%fd1039, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1040, %fd1038, %fd1029, %fd1039;
	mov.f64 	%fd1041, 0d3F81111111122322;
	fma.rn.f64 	%fd1042, %fd1040, %fd1029, %fd1041;
	mov.f64 	%fd1043, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1044, %fd1042, %fd1029, %fd1043;
	mov.f64 	%fd1045, 0d3FC5555555555511;
	fma.rn.f64 	%fd1046, %fd1044, %fd1029, %fd1045;
	mov.f64 	%fd1047, 0d3FE000000000000B;
	fma.rn.f64 	%fd1048, %fd1046, %fd1029, %fd1047;
	mov.f64 	%fd1049, 0d3FF0000000000000;
	fma.rn.f64 	%fd1050, %fd1048, %fd1029, %fd1049;
	fma.rn.f64 	%fd1832, %fd1050, %fd1029, %fd1049;
	abs.s32 	%r241, %r84;
	setp.lt.s32	%p111, %r241, 1023;
	@%p111 bra 	BB0_134;
	bra.uni 	BB0_133;

BB0_134:
	shl.b32 	%r247, %r84, 20;
	add.s32 	%r354, %r247, 1072693248;
	bra.uni 	BB0_135;

BB0_131:
	setp.lt.s32	%p109, %r83, 0;
	selp.f64	%fd1017, 0d0000000000000000, 0d7FF0000000000000, %p109;
	abs.f64 	%fd1018, %fd130;
	setp.gtu.f64	%p110, %fd1018, 0d7FF0000000000000;
	add.f64 	%fd1019, %fd130, %fd130;
	selp.f64	%fd1833, %fd1019, %fd1017, %p110;
	bra.uni 	BB0_136;

BB0_133:
	add.s32 	%r242, %r84, 2046;
	shl.b32 	%r243, %r242, 19;
	and.b32  	%r244, %r243, -1048576;
	shl.b32 	%r245, %r242, 20;
	sub.s32 	%r354, %r245, %r244;
	mov.u32 	%r246, 0;
	mov.b64 	%fd1051, {%r246, %r244};
	mul.f64 	%fd1832, %fd1832, %fd1051;

BB0_135:
	mov.u32 	%r248, 0;
	mov.b64 	%fd1052, {%r248, %r354};
	mul.f64 	%fd1833, %fd1832, %fd1052;

BB0_136:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r249}, %fd1833;
	}
	and.b32  	%r250, %r249, 2147483647;
	setp.ne.s32	%p112, %r250, 2146435072;
	@%p112 bra 	BB0_138;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r251, %temp}, %fd1833;
	}
	setp.eq.s32	%p113, %r251, 0;
	@%p113 bra 	BB0_139;

BB0_138:
	// inline asm
	fma.rn.f64 	%fd1833, %fd1833, %fd131, %fd1833;
	// inline asm

BB0_139:
	setp.neu.f64	%p114, %fd126, 0d3FF0000000000000;
	or.pred  	%p116, %p104, %p114;
	@%p116 bra 	BB0_148;

	mov.b64 	 %rd40, %fd1833;
	xor.b64  	%rd41, %rd40, -9223372036854775808;
	mov.b64 	 %fd1833, %rd41;

BB0_148:
	add.f64 	%fd1839, %fd1839, %fd1833;
	add.s32 	%r344, %r344, 1;
	add.s32 	%r368, %r344, %r1;
	setp.lt.s32	%p122, %r368, 6;
	setp.lt.s32	%p123, %r344, 2;
	and.pred  	%p124, %p122, %p123;
	mov.f64 	%fd1835, %fd1836;
	mov.f64 	%fd1838, %fd1839;
	mov.f64 	%fd1843, %fd1844;
	@%p124 bra 	BB0_83;

BB0_149:
	mov.f64 	%fd1853, 0d0000000000000000;
	mul.f64 	%fd1062, %fd1838, %fd1835;
	sqrt.rn.f64 	%fd1063, %fd1062;
	div.rn.f64 	%fd1064, %fd1843, %fd1063;
	abs.f64 	%fd1065, %fd1064;
	setp.gtu.f64	%p125, %fd1065, 0d7FF0000000000000;
	add.f64 	%fd1066, %fd1064, 0d0000000000000000;
	selp.f64	%fd152, 0dFFF8000000000000, %fd1066, %p125;
	mov.f64 	%fd1850, %fd1853;
	mov.u32 	%r358, 0;
	mov.f64 	%fd1854, %fd1853;
	mov.f64 	%fd1851, %fd1853;
	mov.u32 	%r360, %r358;
	mov.u32 	%r355, %r358;
	@%p1 bra 	BB0_155;

	mov.u32 	%r367, %r1;

BB0_151:
	mov.u32 	%r90, %r367;
	mov.u32 	%r357, %r360;
	mov.u32 	%r359, %r357;
	cvt.s64.s32	%rd1, %r90;
	mul.wide.s32 	%rd44, %r90, 8;
	add.s64 	%rd45, %rd10, %rd44;
	ld.global.f64 	%fd1848, [%rd45];
	abs.f64 	%fd1067, %fd1848;
	setp.gtu.f64	%p127, %fd1067, 0d7FF0000000000000;
	@%p127 bra 	BB0_153;

	shl.b64 	%rd46, %rd1, 3;
	add.s64 	%rd47, %rd11, %rd46;
	ld.global.f64 	%fd1847, [%rd47];
	abs.f64 	%fd1068, %fd1847;
	setp.le.f64	%p128, %fd1068, 0d7FF0000000000000;
	@%p128 bra 	BB0_154;

BB0_153:
	add.s32 	%r359, %r359, -1;
	mov.f64 	%fd1848, 0d0000000000000000;
	mov.f64 	%fd1847, %fd1848;

BB0_154:
	add.f64 	%fd1851, %fd1851, %fd1848;
	add.f64 	%fd1854, %fd1854, %fd1847;
	add.s32 	%r360, %r359, 1;
	add.s32 	%r355, %r355, 1;
	setp.lt.s32	%p129, %r355, 2;
	add.s32 	%r367, %r355, %r1;
	setp.lt.s32	%p130, %r367, 6;
	and.pred  	%p131, %p129, %p130;
	mov.u32 	%r358, %r360;
	mov.f64 	%fd1850, %fd1851;
	mov.f64 	%fd1853, %fd1854;
	@%p131 bra 	BB0_151;

BB0_155:
	setp.lt.s32	%p132, %r358, 1;
	mov.f64 	%fd1862, 0dFFF8000000000000;
	@%p132 bra 	BB0_163;

	cvt.rn.f64.s32	%fd163, %r358;
	div.rn.f64 	%fd164, %fd1850, %fd163;
	div.rn.f64 	%fd165, %fd1853, %fd163;
	mov.f64 	%fd1860, 0d0000000000000000;
	mov.f64 	%fd1861, %fd1860;
	mov.u32 	%r372, 0;
	@%p1 bra 	BB0_162;

	mov.u32 	%r366, %r1;

BB0_158:
	mov.u32 	%r99, %r366;
	cvt.s64.s32	%rd2, %r99;
	mul.wide.s32 	%rd48, %r99, 8;
	add.s64 	%rd49, %rd10, %rd48;
	ld.global.f64 	%fd167, [%rd49];
	abs.f64 	%fd1074, %fd167;
	setp.gtu.f64	%p134, %fd1074, 0d7FF0000000000000;
	mov.f64 	%fd1856, %fd165;
	mov.f64 	%fd1858, %fd164;
	@%p134 bra 	BB0_161;

	shl.b64 	%rd50, %rd2, 3;
	add.s64 	%rd51, %rd11, %rd50;
	ld.global.f64 	%fd168, [%rd51];
	abs.f64 	%fd1075, %fd168;
	setp.gtu.f64	%p135, %fd1075, 0d7FF0000000000000;
	mov.f64 	%fd1855, %fd165;
	mov.f64 	%fd1856, %fd1855;
	mov.f64 	%fd1857, %fd164;
	mov.f64 	%fd1858, %fd1857;
	@%p135 bra 	BB0_161;

	mov.f64 	%fd1856, %fd168;
	mov.f64 	%fd1858, %fd167;

BB0_161:
	mov.f64 	%fd170, %fd1858;
	mov.f64 	%fd169, %fd1856;
	sub.f64 	%fd1076, %fd169, %fd165;
	sub.f64 	%fd1077, %fd170, %fd164;
	fma.rn.f64 	%fd1861, %fd1076, %fd1077, %fd1861;
	add.s32 	%r372, %r372, 1;
	setp.lt.s32	%p136, %r372, 2;
	add.s32 	%r366, %r372, %r1;
	setp.lt.s32	%p137, %r366, 6;
	and.pred  	%p138, %p136, %p137;
	mov.f64 	%fd1860, %fd1861;
	@%p138 bra 	BB0_158;

BB0_162:
	div.rn.f64 	%fd1862, %fd1860, %fd163;

BB0_163:
	cvt.s64.s32	%rd3, %r1;
	mov.f64 	%fd1863, 0d8000000000000000;
	setp.gt.s32	%p139, %r1, 4;
	@%p139 bra 	BB0_166;

	ld.param.u64 	%rd67, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_3];
	shl.b64 	%rd52, %rd3, 3;
	add.s64 	%rd53, %rd67, %rd52;
	ld.global.f64 	%fd175, [%rd53];
	abs.f64 	%fd1080, %fd175;
	setp.gtu.f64	%p140, %fd1080, 0d7FF0000000000000;
	@%p140 bra 	BB0_166;

	mul.f64 	%fd1863, %fd175, 0dBFE6A09E667F3BCC;

BB0_166:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r256}, %fd1863; 
	}
	// inline asm
	setp.lt.s32	%p141, %r256, 1072168960;
	@%p141 bra 	BB0_174;
	bra.uni 	BB0_167;

BB0_174:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r104}, %fd1863;
	}
	and.b32  	%r105, %r104, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r106, %temp}, %fd1863;
	}
	setp.lt.u32	%p147, %r105, 1072693248;
	@%p147 bra 	BB0_180;
	bra.uni 	BB0_175;

BB0_180:
	mul.f64 	%fd1335, %fd1863, %fd1863;
	mov.f64 	%fd1336, 0d3E4D5F4BB7A316F6;
	mov.f64 	%fd1337, 0dBE0A83AA3B08FBC2;
	fma.rn.f64 	%fd1338, %fd1337, %fd1335, %fd1336;
	mov.f64 	%fd1339, 0dBE85BDCE301B3CDF;
	fma.rn.f64 	%fd1340, %fd1338, %fd1335, %fd1339;
	mov.f64 	%fd1341, 0d3EBB978FADB81BC9;
	fma.rn.f64 	%fd1342, %fd1340, %fd1335, %fd1341;
	mov.f64 	%fd1343, 0dBEEF4C99D6AE5FB8;
	fma.rn.f64 	%fd1344, %fd1342, %fd1335, %fd1343;
	mov.f64 	%fd1345, 0d3F1F9A2AF549012E;
	fma.rn.f64 	%fd1346, %fd1344, %fd1335, %fd1345;
	mov.f64 	%fd1347, 0dBF4C02DAFC636A47;
	fma.rn.f64 	%fd1348, %fd1346, %fd1335, %fd1347;
	mov.f64 	%fd1349, 0d3F7565BCCF619AC0;
	fma.rn.f64 	%fd1350, %fd1348, %fd1335, %fd1349;
	mov.f64 	%fd1351, 0dBF9B82CE311E321A;
	fma.rn.f64 	%fd1352, %fd1350, %fd1335, %fd1351;
	mov.f64 	%fd1353, 0d3FBCE2F21A04075C;
	fma.rn.f64 	%fd1354, %fd1352, %fd1335, %fd1353;
	mov.f64 	%fd1355, 0dBFD812746B0379B4;
	fma.rn.f64 	%fd1356, %fd1354, %fd1335, %fd1355;
	mov.f64 	%fd1357, 0d3FF20DD750429B6D;
	fma.rn.f64 	%fd1358, %fd1356, %fd1335, %fd1357;
	mul.f64 	%fd1866, %fd1863, %fd1358;
	bra.uni 	BB0_181;

BB0_167:
	setp.gt.f64	%p142, %fd1863, 0d403B4CCCCCCCCCCD;
	mov.f64 	%fd1867, 0d0000000000000000;
	@%p142 bra 	BB0_182;

	setp.lt.s32	%p143, %r256, 1075052544;
	@%p143 bra 	BB0_170;
	bra.uni 	BB0_169;

BB0_170:
	mov.f64 	%fd1129, 0d3FE20DD7452FBC22;
	mov.f64 	%fd1131, 0d401FD453E105E9A2;
	// inline asm
	fma.rn.f64 	%fd1128, %fd1129, %fd1863, %fd1131;
	// inline asm
	mov.f64 	%fd1135, 0d404B26245B951FB4;
	// inline asm
	fma.rn.f64 	%fd1132, %fd1128, %fd1863, %fd1135;
	// inline asm
	mov.f64 	%fd1139, 0d406C7835DC0F1F49;
	// inline asm
	fma.rn.f64 	%fd1136, %fd1132, %fd1863, %fd1139;
	// inline asm
	mov.f64 	%fd1143, 0d4083AFA471E5C766;
	// inline asm
	fma.rn.f64 	%fd1140, %fd1136, %fd1863, %fd1143;
	// inline asm
	mov.f64 	%fd1147, 0d4091FB514824F49F;
	// inline asm
	fma.rn.f64 	%fd1144, %fd1140, %fd1863, %fd1147;
	// inline asm
	mov.f64 	%fd1151, 0d409450DDEE8272BB;
	// inline asm
	fma.rn.f64 	%fd1148, %fd1144, %fd1863, %fd1151;
	// inline asm
	mov.f64 	%fd1155, 0d4086B952E4ECBC50;
	// inline asm
	fma.rn.f64 	%fd1152, %fd1148, %fd1863, %fd1155;
	// inline asm
	add.f64 	%fd1157, %fd1863, 0d402C35442E99E667;
	mov.f64 	%fd1159, 0d40582F68071A079D;
	// inline asm
	fma.rn.f64 	%fd1156, %fd1157, %fd1863, %fd1159;
	// inline asm
	mov.f64 	%fd1163, 0d4079ABD39A029DAA;
	// inline asm
	fma.rn.f64 	%fd1160, %fd1156, %fd1863, %fd1163;
	// inline asm
	mov.f64 	%fd1167, 0d409230CA327093FD;
	// inline asm
	fma.rn.f64 	%fd1164, %fd1160, %fd1863, %fd1167;
	// inline asm
	mov.f64 	%fd1171, 0d40A174FAB33B54A7;
	// inline asm
	fma.rn.f64 	%fd1168, %fd1164, %fd1863, %fd1171;
	// inline asm
	mov.f64 	%fd1175, 0d40A601508230F980;
	// inline asm
	fma.rn.f64 	%fd1172, %fd1168, %fd1863, %fd1175;
	// inline asm
	mov.f64 	%fd1179, 0d40A091785EC9331E;
	// inline asm
	fma.rn.f64 	%fd1176, %fd1172, %fd1863, %fd1179;
	// inline asm
	mov.f64 	%fd1183, 0d4086B952E52F3622;
	// inline asm
	fma.rn.f64 	%fd1180, %fd1176, %fd1863, %fd1183;
	// inline asm
	div.rn.f64 	%fd1864, %fd1152, %fd1180;
	bra.uni 	BB0_171;

BB0_175:
	setp.lt.u32	%p148, %r105, 2146435072;
	@%p148 bra 	BB0_179;
	bra.uni 	BB0_176;

BB0_179:
	mov.b64 	%fd1256, {%r106, %r105};
	mov.f64 	%fd1257, 0dBCF1384CE38C616A;
	mov.f64 	%fd1258, 0d3C8B9C2B870030E8;
	fma.rn.f64 	%fd1259, %fd1258, %fd1256, %fd1257;
	mov.f64 	%fd1260, 0d3D4458AE9746C2FD;
	fma.rn.f64 	%fd1261, %fd1259, %fd1256, %fd1260;
	mov.f64 	%fd1262, 0dBD8E4A44D4F1AB56;
	fma.rn.f64 	%fd1263, %fd1261, %fd1256, %fd1262;
	mov.f64 	%fd1264, 0d3DCFDF15265C58EE;
	fma.rn.f64 	%fd1265, %fd1263, %fd1256, %fd1264;
	mov.f64 	%fd1266, 0dBE0933832F358D51;
	fma.rn.f64 	%fd1267, %fd1265, %fd1256, %fd1266;
	mov.f64 	%fd1268, 0d3E3F136D3F719446;
	fma.rn.f64 	%fd1269, %fd1267, %fd1256, %fd1268;
	mov.f64 	%fd1270, 0dBE6E94C2FE151B3B;
	fma.rn.f64 	%fd1271, %fd1269, %fd1256, %fd1270;
	mov.f64 	%fd1272, 0d3E985A70310EE0A8;
	fma.rn.f64 	%fd1273, %fd1271, %fd1256, %fd1272;
	mov.f64 	%fd1274, 0dBEBF944DA1520B74;
	fma.rn.f64 	%fd1275, %fd1273, %fd1256, %fd1274;
	mov.f64 	%fd1276, 0d3EE09F503825C543;
	fma.rn.f64 	%fd1277, %fd1275, %fd1256, %fd1276;
	mov.f64 	%fd1278, 0dBEFBEEFE9F949E59;
	fma.rn.f64 	%fd1279, %fd1277, %fd1256, %fd1278;
	mov.f64 	%fd1280, 0d3F11D785C6E28857;
	fma.rn.f64 	%fd1281, %fd1279, %fd1256, %fd1280;
	mov.f64 	%fd1282, 0dBF1D866B223048C7;
	fma.rn.f64 	%fd1283, %fd1281, %fd1256, %fd1282;
	mov.f64 	%fd1284, 0d3EF258F0847E8908;
	fma.rn.f64 	%fd1285, %fd1283, %fd1256, %fd1284;
	mov.f64 	%fd1286, 0d3F429CFC58DBB776;
	fma.rn.f64 	%fd1287, %fd1285, %fd1256, %fd1286;
	mov.f64 	%fd1288, 0dBF5BE16D3F71F3C5;
	fma.rn.f64 	%fd1289, %fd1287, %fd1256, %fd1288;
	mov.f64 	%fd1290, 0d3F2E8BDA60326B1A;
	fma.rn.f64 	%fd1291, %fd1289, %fd1256, %fd1290;
	mov.f64 	%fd1292, 0d3F938FB20B0988A6;
	fma.rn.f64 	%fd1293, %fd1291, %fd1256, %fd1292;
	mov.f64 	%fd1294, 0dBFBA4E3A80F64E33;
	fma.rn.f64 	%fd1295, %fd1293, %fd1256, %fd1294;
	mov.f64 	%fd1296, 0dBFE45F3E88093928;
	fma.rn.f64 	%fd1297, %fd1295, %fd1256, %fd1296;
	mov.f64 	%fd1298, 0dBFF20DD599CAEEA0;
	fma.rn.f64 	%fd1299, %fd1297, %fd1256, %fd1298;
	mov.f64 	%fd1300, 0dBE883BE1E31CE133;
	fma.rn.f64 	%fd1301, %fd1299, %fd1256, %fd1300;
	mov.f64 	%fd1302, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1303, %fd1301, %fd1302;
	mov.f64 	%fd1304, 0d4338000000000000;
	add.rn.f64 	%fd1305, %fd1303, %fd1304;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r272, %temp}, %fd1305;
	}
	mov.f64 	%fd1306, 0dC338000000000000;
	add.rn.f64 	%fd1307, %fd1305, %fd1306;
	mov.f64 	%fd1308, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1309, %fd1307, %fd1308, %fd1301;
	mov.f64 	%fd1310, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1311, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1312, %fd1311, %fd1309, %fd1310;
	mov.f64 	%fd1313, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1314, %fd1312, %fd1309, %fd1313;
	mov.f64 	%fd1315, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1316, %fd1314, %fd1309, %fd1315;
	mov.f64 	%fd1317, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1318, %fd1316, %fd1309, %fd1317;
	mov.f64 	%fd1319, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1320, %fd1318, %fd1309, %fd1319;
	mov.f64 	%fd1321, 0d3F81111111122322;
	fma.rn.f64 	%fd1322, %fd1320, %fd1309, %fd1321;
	mov.f64 	%fd1323, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1324, %fd1322, %fd1309, %fd1323;
	mov.f64 	%fd1325, 0d3FC5555555555511;
	fma.rn.f64 	%fd1326, %fd1324, %fd1309, %fd1325;
	mov.f64 	%fd1327, 0d3FE000000000000B;
	fma.rn.f64 	%fd1328, %fd1326, %fd1309, %fd1327;
	mov.f64 	%fd1329, 0d3FF0000000000000;
	fma.rn.f64 	%fd1330, %fd1328, %fd1309, %fd1329;
	fma.rn.f64 	%fd1331, %fd1330, %fd1309, %fd1329;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r273}, %fd1331;
	}
	shl.b32 	%r274, %r272, 20;
	add.s32 	%r275, %r273, %r274;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r276, %temp}, %fd1331;
	}
	mov.b64 	%fd1332, {%r276, %r275};
	sub.f64 	%fd1333, %fd1329, %fd1332;
	setp.gt.u32	%p152, %r105, 1075294207;
	selp.f64	%fd1334, 0d3FF0000000000000, %fd1333, %p152;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r277, %temp}, %fd1334;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r278}, %fd1334;
	}
	and.b32  	%r279, %r104, -2147483648;
	or.b32  	%r280, %r278, %r279;
	mov.b64 	%fd1866, {%r277, %r280};
	bra.uni 	BB0_181;

BB0_169:
	rcp.rn.f64 	%fd1127, %fd1863;
	mul.rn.f64 	%fd1125, %fd1127, %fd1127;
	mov.f64 	%fd1084, 0dC1186DF84479631D;
	mov.f64 	%fd1086, 0d41019A6E9A7FFBB8;
	// inline asm
	fma.rn.f64 	%fd1083, %fd1084, %fd1125, %fd1086;
	// inline asm
	mov.f64 	%fd1090, 0dC0DB040BE3D5CA18;
	// inline asm
	fma.rn.f64 	%fd1087, %fd1083, %fd1125, %fd1090;
	// inline asm
	mov.f64 	%fd1094, 0d40B012760EE009A0;
	// inline asm
	fma.rn.f64 	%fd1091, %fd1087, %fd1125, %fd1094;
	// inline asm
	mov.f64 	%fd1098, 0dC082587AE4008D0E;
	// inline asm
	fma.rn.f64 	%fd1095, %fd1091, %fd1125, %fd1098;
	// inline asm
	mov.f64 	%fd1102, 0d4056DF5D938ACAFE;
	// inline asm
	fma.rn.f64 	%fd1099, %fd1095, %fd1125, %fd1102;
	// inline asm
	mov.f64 	%fd1106, 0dC030A8D46D765681;
	// inline asm
	fma.rn.f64 	%fd1103, %fd1099, %fd1125, %fd1106;
	// inline asm
	mov.f64 	%fd1110, 0d400D9EAE0C665C75;
	// inline asm
	fma.rn.f64 	%fd1107, %fd1103, %fd1125, %fd1110;
	// inline asm
	mov.f64 	%fd1114, 0dBFF0ECF9C8880942;
	// inline asm
	fma.rn.f64 	%fd1111, %fd1107, %fd1125, %fd1114;
	// inline asm
	mov.f64 	%fd1118, 0d3FDB14C2F82A33F7;
	// inline asm
	fma.rn.f64 	%fd1115, %fd1111, %fd1125, %fd1118;
	// inline asm
	mov.f64 	%fd1122, 0dBFD20DD75042844F;
	// inline asm
	fma.rn.f64 	%fd1119, %fd1115, %fd1125, %fd1122;
	// inline asm
	mov.f64 	%fd1126, 0d3FE20DD750429B6B;
	// inline asm
	fma.rn.f64 	%fd1123, %fd1119, %fd1125, %fd1126;
	// inline asm
	mul.rn.f64 	%fd1864, %fd1123, %fd1127;

BB0_171:
	mul.rn.f64 	%fd1184, %fd1863, %fd1863;
	neg.f64 	%fd181, %fd1184;
	mov.f64 	%fd1185, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1865, %fd181, %fd1185;
	abs.f64 	%fd183, %fd1865;
	setp.ge.f64	%p144, %fd183, 0d4330000000000000;
	@%p144 bra 	BB0_173;

	add.f64 	%fd1186, %fd183, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd1187, %fd1186;
	setp.lt.f64	%p145, %fd183, 0d3FE0000000000000;
	selp.f64	%fd1188, 0d0000000000000000, %fd1187, %p145;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r257, %temp}, %fd1188;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r258}, %fd1188;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd1865;
	}
	and.b32  	%r260, %r259, -2147483648;
	or.b32  	%r261, %r258, %r260;
	mov.b64 	%fd1865, {%r257, %r261};

BB0_173:
	mov.f64 	%fd1191, 0dBFE62E42FEFA39EF;
	// inline asm
	fma.rn.f64 	%fd1189, %fd1865, %fd1191, %fd181;
	// inline asm
	mov.f64 	%fd1195, 0dBC7ABC9E3B39803F;
	// inline asm
	fma.rn.f64 	%fd1193, %fd1865, %fd1195, %fd1189;
	// inline asm
	cvt.rzi.s32.f64	%r264, %fd1865;
	setp.lt.s32	%p146, %r264, -1020;
	add.s32 	%r265, %r264, 55;
	selp.f64	%fd1254, 0d3C90000000000000, 0d4000000000000000, %p146;
	selp.b32	%r266, %r265, %r264, %p146;
	mov.f64 	%fd1198, 0d3E21F07FCCF58BAD;
	mov.f64 	%fd1200, 0d3E5AFD81DA6C3BAF;
	// inline asm
	fma.rn.f64 	%fd1197, %fd1198, %fd1193, %fd1200;
	// inline asm
	mov.f64 	%fd1204, 0d3E927E55F60F80E6;
	// inline asm
	fma.rn.f64 	%fd1201, %fd1197, %fd1193, %fd1204;
	// inline asm
	mov.f64 	%fd1208, 0d3EC71DDA8F02D666;
	// inline asm
	fma.rn.f64 	%fd1205, %fd1201, %fd1193, %fd1208;
	// inline asm
	mov.f64 	%fd1212, 0d3EFA01A013B894E0;
	// inline asm
	fma.rn.f64 	%fd1209, %fd1205, %fd1193, %fd1212;
	// inline asm
	mov.f64 	%fd1216, 0d3F2A01A01D3AF788;
	// inline asm
	fma.rn.f64 	%fd1213, %fd1209, %fd1193, %fd1216;
	// inline asm
	mov.f64 	%fd1220, 0d3F56C16C16C3A1EC;
	// inline asm
	fma.rn.f64 	%fd1217, %fd1213, %fd1193, %fd1220;
	// inline asm
	mov.f64 	%fd1224, 0d3F81111111109161;
	// inline asm
	fma.rn.f64 	%fd1221, %fd1217, %fd1193, %fd1224;
	// inline asm
	mov.f64 	%fd1228, 0d3FA55555555554C1;
	// inline asm
	fma.rn.f64 	%fd1225, %fd1221, %fd1193, %fd1228;
	// inline asm
	mov.f64 	%fd1232, 0d3FC555555555556F;
	// inline asm
	fma.rn.f64 	%fd1229, %fd1225, %fd1193, %fd1232;
	// inline asm
	mov.f64 	%fd1236, 0d3FE0000000000000;
	// inline asm
	fma.rn.f64 	%fd1233, %fd1229, %fd1193, %fd1236;
	// inline asm
	mul.rn.f64 	%fd1238, %fd1233, %fd1193;
	// inline asm
	fma.rn.f64 	%fd1237, %fd1238, %fd1193, %fd1193;
	// inline asm
	add.s32 	%r267, %r266, 1022;
	shl.b32 	%r263, %r267, 20;
	mov.u32 	%r262, 0;
	// inline asm
	mov.b64 	%fd1241, {%r262, %r263};
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1242, %fd1237, %fd1241, %fd1241;
	// inline asm
	mul.rn.f64 	%fd1253, %fd1242, %fd1254;
	neg.f64 	%fd1252, %fd1253;
	// inline asm
	fma.rn.f64 	%fd1246, %fd1863, %fd1863, %fd181;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1250, %fd1246, %fd1252, %fd1253;
	// inline asm
	mul.rn.f64 	%fd1867, %fd1864, %fd1250;
	bra.uni 	BB0_182;

BB0_176:
	setp.eq.s32	%p149, %r105, 2146435072;
	setp.eq.s32	%p150, %r106, 0;
	and.pred  	%p151, %p149, %p150;
	@%p151 bra 	BB0_178;
	bra.uni 	BB0_177;

BB0_178:
	mov.f64 	%fd1255, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r268, %temp}, %fd1255;
	}
	and.b32  	%r269, %r104, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r270}, %fd1255;
	}
	or.b32  	%r271, %r270, %r269;
	mov.b64 	%fd1866, {%r268, %r271};
	bra.uni 	BB0_181;

BB0_177:
	add.f64 	%fd1866, %fd1863, %fd1863;

BB0_181:
	mov.f64 	%fd1359, 0d3FF0000000000000;
	sub.f64 	%fd1867, %fd1359, %fd1866;

BB0_182:
	ld.param.u64 	%rd66, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_2];
	fma.rn.f64 	%fd194, %fd1867, 0d3FE0000000000000, 0d0000000000000000;
	shl.b64 	%rd54, %rd3, 3;
	add.s64 	%rd4, %rd66, %rd54;
	mov.f64 	%fd1869, 0d0000000000000000;
	mov.f64 	%fd1868, %fd1869;
	@%p139 bra 	BB0_184;

	ld.global.f64 	%fd1362, [%rd4];
	abs.f64 	%fd1363, %fd1362;
	setp.gtu.f64	%p154, %fd1363, 0d7FF0000000000000;
	add.f64 	%fd1364, %fd1362, 0d0000000000000000;
	selp.f64	%fd1868, 0d0000000000000000, %fd1364, %p154;
	selp.f64	%fd1869, 0d0000000000000000, 0d3FF0000000000000, %p154;

BB0_184:
	ld.param.u64 	%rd68, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_1];
	add.s64 	%rd5, %rd68, %rd54;
	@%p139 bra 	BB0_186;

	ld.global.f64 	%fd1365, [%rd5];
	abs.f64 	%fd1366, %fd1365;
	setp.gtu.f64	%p156, %fd1366, 0d7FF0000000000000;
	add.f64 	%fd1367, %fd1868, %fd1365;
	selp.f64	%fd1868, %fd1868, %fd1367, %p156;
	add.f64 	%fd1368, %fd1869, 0d3FF0000000000000;
	selp.f64	%fd1869, %fd1869, %fd1368, %p156;

BB0_186:
	setp.eq.f64	%p157, %fd1869, 0d3FF0000000000000;
	mov.f64 	%fd1872, 0d3FF0000000000000;
	@%p157 bra 	BB0_217;

	abs.f64 	%fd203, %fd1869;
	setp.gtu.f64	%p158, %fd203, 0d7FF0000000000000;
	@%p158 bra 	BB0_216;
	bra.uni 	BB0_188;

BB0_216:
	add.f64 	%fd1872, %fd1869, 0dBFF0000000000000;
	bra.uni 	BB0_217;

BB0_188:
	setp.eq.f64	%p159, %fd1869, 0d7FF0000000000000;
	mov.f64 	%fd1370, 0dBFF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r107}, %fd1370;
	}
	@%p159 bra 	BB0_215;
	bra.uni 	BB0_189;

BB0_215:
	setp.gt.s32	%p181, %r107, -1;
	selp.f64	%fd1872, 0d7FF0000000000000, 0d0000000000000000, %p181;
	bra.uni 	BB0_217;

BB0_189:
	and.b32  	%r281, %r107, 2147483647;
	setp.ne.s32	%p160, %r281, 2146435072;
	@%p160 bra 	BB0_191;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r282, %temp}, %fd1370;
	}
	setp.eq.s32	%p161, %r282, 0;
	@%p161 bra 	BB0_213;

BB0_191:
	mov.f64 	%fd1373, 0d3FE0000000000000;
	mul.rn.f64 	%fd1374, %fd1373, %fd1370;
	cvt.rzi.f64.f64	%fd1375, %fd1374;
	mov.f64 	%fd1376, 0d4000000000000000;
	mul.rn.f64 	%fd1377, %fd1376, %fd1375;
	sub.f64 	%fd1378, %fd1370, %fd1377;
	abs.f64 	%fd204, %fd1378;
	setp.eq.f64	%p162, %fd1869, 0d0000000000000000;
	@%p162 bra 	BB0_212;
	bra.uni 	BB0_192;

BB0_212:
	setp.eq.f64	%p178, %fd204, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1558, %fd1869;
	mov.f64 	%fd1559, 0d0000000000000000;
	rcp.rn.f64 	%fd1560, %fd1559;
	selp.f64	%fd1872, %fd1558, %fd1560, %p178;
	bra.uni 	BB0_217;

BB0_192:
	setp.eq.f64	%p163, %fd1869, 0dFFF0000000000000;
	@%p163 bra 	BB0_210;
	bra.uni 	BB0_193;

BB0_210:
	div.rn.f64 	%fd1872, %fd1370, %fd1869;
	setp.neu.f64	%p177, %fd204, 0d3FF0000000000000;
	@%p177 bra 	BB0_217;

	mov.b64 	 %rd58, %fd1872;
	xor.b64  	%rd59, %rd58, -9223372036854775808;
	mov.b64 	 %fd1872, %rd59;
	bra.uni 	BB0_217;

BB0_48:
	and.b32  	%r175, %r28, 2147483647;
	setp.ne.s32	%p43, %r175, 2146435072;
	@%p43 bra 	BB0_50;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r176, %temp}, %fd473;
	}
	setp.eq.s32	%p44, %r176, 0;
	@%p44 bra 	BB0_70;

BB0_50:
	mov.f64 	%fd476, 0d3FE0000000000000;
	mul.rn.f64 	%fd477, %fd476, %fd473;
	cvt.rzi.f64.f64	%fd478, %fd477;
	mov.f64 	%fd479, 0d4000000000000000;
	mul.rn.f64 	%fd480, %fd479, %fd478;
	sub.f64 	%fd481, %fd473, %fd480;
	abs.f64 	%fd51, %fd481;
	setp.eq.f64	%p45, %fd1809, 0dFFF0000000000000;
	@%p45 bra 	BB0_68;
	bra.uni 	BB0_51;

BB0_68:
	div.rn.f64 	%fd1814, %fd473, %fd1809;
	setp.neu.f64	%p59, %fd51, 0d3FF0000000000000;
	@%p59 bra 	BB0_74;

	mov.b64 	 %rd28, %fd1814;
	xor.b64  	%rd29, %rd28, -9223372036854775808;
	mov.b64 	 %fd1814, %rd29;
	bra.uni 	BB0_74;

BB0_213:
	setp.eq.f64	%p179, %fd1869, 0dBFF0000000000000;
	@%p179 bra 	BB0_217;

	setp.gt.f64	%p180, %fd203, 0d3FF0000000000000;
	mov.f64 	%fd1562, 0d0000000000000000;
	rcp.rn.f64 	%fd1563, %fd1562;
	selp.f64	%fd1872, 0d0000000000000000, %fd1563, %p180;
	bra.uni 	BB0_217;

BB0_193:
	setp.geu.f64	%p164, %fd1869, 0d0000000000000000;
	@%p164 bra 	BB0_195;

	cvt.rzi.f64.f64	%fd1381, %fd1370;
	setp.neu.f64	%p165, %fd1381, 0dBFF0000000000000;
	mov.f64 	%fd1872, 0dFFF8000000000000;
	@%p165 bra 	BB0_217;

BB0_195:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r374}, %fd203; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r373, hi}, %fd203; 
	}
	// inline asm
	bfe.u32 	%r375, %r374, 20, 11;
	setp.ne.s32	%p166, %r375, 0;
	@%p166 bra 	BB0_197;

	mov.f64 	%fd1386, 0d4350000000000000;
	mul.rn.f64 	%fd1385, %fd203, %fd1386;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r374}, %fd1385; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r373, hi}, %fd1385; 
	}
	// inline asm
	bfe.u32 	%r287, %r374, 20, 11;
	add.s32 	%r375, %r287, -54;

BB0_197:
	add.s32 	%r376, %r375, -1023;
	and.b32  	%r290, %r374, -2146435073;
	or.b32  	%r289, %r290, 1072693248;
	// inline asm
	mov.b64 	%fd1870, {%r373, %r289};
	// inline asm
	setp.lt.u32	%p167, %r289, 1073127583;
	@%p167 bra 	BB0_199;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r291, hi}, %fd1870; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r292}, %fd1870; 
	}
	// inline asm
	add.s32 	%r294, %r292, -1048576;
	// inline asm
	mov.b64 	%fd1870, {%r291, %r294};
	// inline asm
	add.s32 	%r376, %r375, -1022;

BB0_199:
	add.f64 	%fd1475, %fd1870, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1476, %fd1475;
	add.f64 	%fd1417, %fd1870, 0dBFF0000000000000;
	mul.rn.f64 	%fd1477, %fd1417, %fd1476;
	add.f64 	%fd1465, %fd1477, %fd1477;
	mul.rn.f64 	%fd1413, %fd1465, %fd1465;
	mov.f64 	%fd1392, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd1394, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd1391, %fd1392, %fd1413, %fd1394;
	// inline asm
	mov.f64 	%fd1398, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd1395, %fd1391, %fd1413, %fd1398;
	// inline asm
	mov.f64 	%fd1402, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd1399, %fd1395, %fd1413, %fd1402;
	// inline asm
	mov.f64 	%fd1406, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd1403, %fd1399, %fd1413, %fd1406;
	// inline asm
	mov.f64 	%fd1410, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd1407, %fd1403, %fd1413, %fd1410;
	// inline asm
	mov.f64 	%fd1414, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd1411, %fd1407, %fd1413, %fd1414;
	// inline asm
	mul.rn.f64 	%fd1478, %fd1411, %fd1413;
	sub.f64 	%fd1479, %fd1417, %fd1465;
	mul.rn.f64 	%fd1418, %fd1376, %fd1479;
	neg.f64 	%fd1416, %fd1465;
	// inline asm
	fma.rn.f64 	%fd1415, %fd1416, %fd1417, %fd1418;
	// inline asm
	mul.rn.f64 	%fd1461, %fd1476, %fd1415;
	add.f64 	%fd1481, %fd1478, 0d3FB5555555555555;
	mov.f64 	%fd1482, 0d3FB5555555555555;
	sub.f64 	%fd1483, %fd1482, %fd1481;
	add.f64 	%fd1484, %fd1478, %fd1483;
	add.f64 	%fd1485, %fd1484, 0d0000000000000000;
	add.f64 	%fd1486, %fd1485, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd1428, %fd1481, %fd1486;
	sub.f64 	%fd1487, %fd1481, %fd1428;
	add.f64 	%fd1432, %fd1486, %fd1487;
	mul.rn.f64 	%fd1488, %fd1428, %fd1465;
	neg.f64 	%fd1422, %fd1488;
	// inline asm
	fma.rn.f64 	%fd1419, %fd1428, %fd1465, %fd1422;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1423, %fd1432, %fd1461, %fd1419;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1427, %fd1428, %fd1461, %fd1423;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1431, %fd1432, %fd1465, %fd1427;
	// inline asm
	add.f64 	%fd1444, %fd1488, %fd1431;
	sub.f64 	%fd1489, %fd1488, %fd1444;
	add.f64 	%fd1448, %fd1431, %fd1489;
	mul.rn.f64 	%fd1490, %fd1444, %fd1465;
	neg.f64 	%fd1438, %fd1490;
	// inline asm
	fma.rn.f64 	%fd1435, %fd1444, %fd1465, %fd1438;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1439, %fd1448, %fd1461, %fd1435;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1443, %fd1444, %fd1461, %fd1439;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1447, %fd1448, %fd1465, %fd1443;
	// inline asm
	add.f64 	%fd1460, %fd1490, %fd1447;
	sub.f64 	%fd1491, %fd1490, %fd1460;
	add.f64 	%fd1464, %fd1447, %fd1491;
	mul.rn.f64 	%fd1492, %fd1460, %fd1465;
	neg.f64 	%fd1454, %fd1492;
	// inline asm
	fma.rn.f64 	%fd1451, %fd1460, %fd1465, %fd1454;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1455, %fd1464, %fd1461, %fd1451;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1459, %fd1460, %fd1461, %fd1455;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1463, %fd1464, %fd1465, %fd1459;
	// inline asm
	add.f64 	%fd1493, %fd1492, %fd1463;
	sub.f64 	%fd1494, %fd1492, %fd1493;
	add.f64 	%fd1495, %fd1463, %fd1494;
	add.f64 	%fd1496, %fd1465, %fd1493;
	sub.f64 	%fd1497, %fd1465, %fd1496;
	add.f64 	%fd1498, %fd1493, %fd1497;
	add.f64 	%fd1499, %fd1495, %fd1498;
	add.f64 	%fd1500, %fd1461, %fd1499;
	add.f64 	%fd1501, %fd1496, %fd1500;
	sub.f64 	%fd1502, %fd1496, %fd1501;
	add.f64 	%fd1503, %fd1500, %fd1502;
	cvt.rn.f64.s32	%fd1504, %r376;
	mov.f64 	%fd1505, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd1506, %fd1504, %fd1505;
	mov.f64 	%fd1507, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd1508, %fd1504, %fd1507;
	add.f64 	%fd1509, %fd1506, %fd1501;
	sub.f64 	%fd1510, %fd1506, %fd1509;
	add.f64 	%fd1511, %fd1501, %fd1510;
	add.f64 	%fd1512, %fd1503, %fd1511;
	add.f64 	%fd1513, %fd1508, %fd1512;
	add.f64 	%fd1468, %fd1509, %fd1513;
	sub.f64 	%fd1514, %fd1509, %fd1468;
	add.f64 	%fd1472, %fd1513, %fd1514;
	mul.rn.f64 	%fd1515, %fd1468, %fd1370;
	neg.f64 	%fd1470, %fd1515;
	// inline asm
	fma.rn.f64 	%fd1467, %fd1468, %fd1370, %fd1470;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1471, %fd1472, %fd1370, %fd1467;
	// inline asm
	add.f64 	%fd208, %fd1515, %fd1471;
	sub.f64 	%fd1516, %fd1515, %fd208;
	add.f64 	%fd209, %fd1471, %fd1516;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd208;
	}
	mov.b32 	 %f9, %r120;
	abs.f32 	%f10, %f9;
	setp.lt.f32	%p168, %f10, 0f40874911;
	@%p168 bra 	BB0_201;
	bra.uni 	BB0_200;

BB0_201:
	mov.f64 	%fd1520, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1521, %fd208, %fd1520;
	mov.f64 	%fd1522, 0d4338000000000000;
	add.rn.f64 	%fd1523, %fd1521, %fd1522;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd1523;
	}
	mov.f64 	%fd1524, 0dC338000000000000;
	add.rn.f64 	%fd1525, %fd1523, %fd1524;
	mov.f64 	%fd1526, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1527, %fd1525, %fd1526, %fd208;
	mov.f64 	%fd1528, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd1529, %fd1525, %fd1528, %fd1527;
	mov.f64 	%fd1530, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1531, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1532, %fd1531, %fd1529, %fd1530;
	mov.f64 	%fd1533, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1534, %fd1532, %fd1529, %fd1533;
	mov.f64 	%fd1535, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1536, %fd1534, %fd1529, %fd1535;
	mov.f64 	%fd1537, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1538, %fd1536, %fd1529, %fd1537;
	mov.f64 	%fd1539, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1540, %fd1538, %fd1529, %fd1539;
	mov.f64 	%fd1541, 0d3F81111111122322;
	fma.rn.f64 	%fd1542, %fd1540, %fd1529, %fd1541;
	mov.f64 	%fd1543, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1544, %fd1542, %fd1529, %fd1543;
	mov.f64 	%fd1545, 0d3FC5555555555511;
	fma.rn.f64 	%fd1546, %fd1544, %fd1529, %fd1545;
	mov.f64 	%fd1547, 0d3FE000000000000B;
	fma.rn.f64 	%fd1548, %fd1546, %fd1529, %fd1547;
	mov.f64 	%fd1549, 0d3FF0000000000000;
	fma.rn.f64 	%fd1550, %fd1548, %fd1529, %fd1549;
	fma.rn.f64 	%fd1871, %fd1550, %fd1529, %fd1549;
	abs.s32 	%r295, %r121;
	setp.lt.s32	%p171, %r295, 1023;
	@%p171 bra 	BB0_203;
	bra.uni 	BB0_202;

BB0_203:
	shl.b32 	%r301, %r121, 20;
	add.s32 	%r377, %r301, 1072693248;
	bra.uni 	BB0_204;

BB0_51:
	setp.geu.f64	%p46, %fd1809, 0d0000000000000000;
	@%p46 bra 	BB0_53;

	cvt.rzi.f64.f64	%fd484, %fd473;
	setp.neu.f64	%p47, %fd484, 0dBFF0000000000000;
	mov.f64 	%fd1814, 0dFFF8000000000000;
	@%p47 bra 	BB0_74;

BB0_53:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r339}, %fd50; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r338, hi}, %fd50; 
	}
	// inline asm
	bfe.u32 	%r340, %r339, 20, 11;
	setp.ne.s32	%p48, %r340, 0;
	@%p48 bra 	BB0_55;

	mov.f64 	%fd489, 0d4350000000000000;
	mul.rn.f64 	%fd488, %fd50, %fd489;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r339}, %fd488; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r338, hi}, %fd488; 
	}
	// inline asm
	bfe.u32 	%r181, %r339, 20, 11;
	add.s32 	%r340, %r181, -54;

BB0_55:
	add.s32 	%r341, %r340, -1023;
	and.b32  	%r184, %r339, -2146435073;
	or.b32  	%r183, %r184, 1072693248;
	// inline asm
	mov.b64 	%fd1812, {%r338, %r183};
	// inline asm
	setp.lt.u32	%p49, %r183, 1073127583;
	@%p49 bra 	BB0_57;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r185, hi}, %fd1812; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r186}, %fd1812; 
	}
	// inline asm
	add.s32 	%r188, %r186, -1048576;
	// inline asm
	mov.b64 	%fd1812, {%r185, %r188};
	// inline asm
	add.s32 	%r341, %r340, -1022;

BB0_57:
	add.f64 	%fd578, %fd1812, 0d3FF0000000000000;
	rcp.rn.f64 	%fd579, %fd578;
	add.f64 	%fd520, %fd1812, 0dBFF0000000000000;
	mul.rn.f64 	%fd580, %fd520, %fd579;
	add.f64 	%fd568, %fd580, %fd580;
	mul.rn.f64 	%fd516, %fd568, %fd568;
	mov.f64 	%fd495, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd497, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd494, %fd495, %fd516, %fd497;
	// inline asm
	mov.f64 	%fd501, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd498, %fd494, %fd516, %fd501;
	// inline asm
	mov.f64 	%fd505, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd502, %fd498, %fd516, %fd505;
	// inline asm
	mov.f64 	%fd509, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd506, %fd502, %fd516, %fd509;
	// inline asm
	mov.f64 	%fd513, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd510, %fd506, %fd516, %fd513;
	// inline asm
	mov.f64 	%fd517, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd514, %fd510, %fd516, %fd517;
	// inline asm
	mul.rn.f64 	%fd581, %fd514, %fd516;
	sub.f64 	%fd582, %fd520, %fd568;
	mul.rn.f64 	%fd521, %fd479, %fd582;
	neg.f64 	%fd519, %fd568;
	// inline asm
	fma.rn.f64 	%fd518, %fd519, %fd520, %fd521;
	// inline asm
	mul.rn.f64 	%fd564, %fd579, %fd518;
	add.f64 	%fd584, %fd581, 0d3FB5555555555555;
	mov.f64 	%fd585, 0d3FB5555555555555;
	sub.f64 	%fd586, %fd585, %fd584;
	add.f64 	%fd587, %fd581, %fd586;
	add.f64 	%fd588, %fd587, 0d0000000000000000;
	add.f64 	%fd589, %fd588, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd531, %fd584, %fd589;
	sub.f64 	%fd590, %fd584, %fd531;
	add.f64 	%fd535, %fd589, %fd590;
	mul.rn.f64 	%fd591, %fd531, %fd568;
	neg.f64 	%fd525, %fd591;
	// inline asm
	fma.rn.f64 	%fd522, %fd531, %fd568, %fd525;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd526, %fd535, %fd564, %fd522;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd530, %fd531, %fd564, %fd526;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd534, %fd535, %fd568, %fd530;
	// inline asm
	add.f64 	%fd547, %fd591, %fd534;
	sub.f64 	%fd592, %fd591, %fd547;
	add.f64 	%fd551, %fd534, %fd592;
	mul.rn.f64 	%fd593, %fd547, %fd568;
	neg.f64 	%fd541, %fd593;
	// inline asm
	fma.rn.f64 	%fd538, %fd547, %fd568, %fd541;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd542, %fd551, %fd564, %fd538;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd546, %fd547, %fd564, %fd542;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd550, %fd551, %fd568, %fd546;
	// inline asm
	add.f64 	%fd563, %fd593, %fd550;
	sub.f64 	%fd594, %fd593, %fd563;
	add.f64 	%fd567, %fd550, %fd594;
	mul.rn.f64 	%fd595, %fd563, %fd568;
	neg.f64 	%fd557, %fd595;
	// inline asm
	fma.rn.f64 	%fd554, %fd563, %fd568, %fd557;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd558, %fd567, %fd564, %fd554;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd562, %fd563, %fd564, %fd558;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd566, %fd567, %fd568, %fd562;
	// inline asm
	add.f64 	%fd596, %fd595, %fd566;
	sub.f64 	%fd597, %fd595, %fd596;
	add.f64 	%fd598, %fd566, %fd597;
	add.f64 	%fd599, %fd568, %fd596;
	sub.f64 	%fd600, %fd568, %fd599;
	add.f64 	%fd601, %fd596, %fd600;
	add.f64 	%fd602, %fd598, %fd601;
	add.f64 	%fd603, %fd564, %fd602;
	add.f64 	%fd604, %fd599, %fd603;
	sub.f64 	%fd605, %fd599, %fd604;
	add.f64 	%fd606, %fd603, %fd605;
	cvt.rn.f64.s32	%fd607, %r341;
	mov.f64 	%fd608, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd609, %fd607, %fd608;
	mov.f64 	%fd610, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd611, %fd607, %fd610;
	add.f64 	%fd612, %fd609, %fd604;
	sub.f64 	%fd613, %fd609, %fd612;
	add.f64 	%fd614, %fd604, %fd613;
	add.f64 	%fd615, %fd606, %fd614;
	add.f64 	%fd616, %fd611, %fd615;
	add.f64 	%fd571, %fd612, %fd616;
	sub.f64 	%fd617, %fd612, %fd571;
	add.f64 	%fd575, %fd616, %fd617;
	mul.rn.f64 	%fd618, %fd571, %fd473;
	neg.f64 	%fd573, %fd618;
	// inline asm
	fma.rn.f64 	%fd570, %fd571, %fd473, %fd573;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd574, %fd575, %fd473, %fd570;
	// inline asm
	add.f64 	%fd55, %fd618, %fd574;
	sub.f64 	%fd619, %fd618, %fd55;
	add.f64 	%fd56, %fd574, %fd619;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r41}, %fd55;
	}
	mov.b32 	 %f3, %r41;
	abs.f32 	%f4, %f3;
	setp.lt.f32	%p50, %f4, 0f40874911;
	@%p50 bra 	BB0_59;
	bra.uni 	BB0_58;

BB0_59:
	mov.f64 	%fd623, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd624, %fd55, %fd623;
	mov.f64 	%fd625, 0d4338000000000000;
	add.rn.f64 	%fd626, %fd624, %fd625;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd626;
	}
	mov.f64 	%fd627, 0dC338000000000000;
	add.rn.f64 	%fd628, %fd626, %fd627;
	mov.f64 	%fd629, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd630, %fd628, %fd629, %fd55;
	mov.f64 	%fd631, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd632, %fd628, %fd631, %fd630;
	mov.f64 	%fd633, 0d3E928AF3FCA213EA;
	mov.f64 	%fd634, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd635, %fd634, %fd632, %fd633;
	mov.f64 	%fd636, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd637, %fd635, %fd632, %fd636;
	mov.f64 	%fd638, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd639, %fd637, %fd632, %fd638;
	mov.f64 	%fd640, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd641, %fd639, %fd632, %fd640;
	mov.f64 	%fd642, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd643, %fd641, %fd632, %fd642;
	mov.f64 	%fd644, 0d3F81111111122322;
	fma.rn.f64 	%fd645, %fd643, %fd632, %fd644;
	mov.f64 	%fd646, 0d3FA55555555502A1;
	fma.rn.f64 	%fd647, %fd645, %fd632, %fd646;
	mov.f64 	%fd648, 0d3FC5555555555511;
	fma.rn.f64 	%fd649, %fd647, %fd632, %fd648;
	mov.f64 	%fd650, 0d3FE000000000000B;
	fma.rn.f64 	%fd651, %fd649, %fd632, %fd650;
	mov.f64 	%fd652, 0d3FF0000000000000;
	fma.rn.f64 	%fd653, %fd651, %fd632, %fd652;
	fma.rn.f64 	%fd1813, %fd653, %fd632, %fd652;
	abs.s32 	%r189, %r42;
	setp.lt.s32	%p53, %r189, 1023;
	@%p53 bra 	BB0_61;
	bra.uni 	BB0_60;

BB0_61:
	shl.b32 	%r195, %r42, 20;
	add.s32 	%r342, %r195, 1072693248;
	bra.uni 	BB0_62;

BB0_200:
	setp.lt.s32	%p169, %r120, 0;
	selp.f64	%fd1517, 0d0000000000000000, 0d7FF0000000000000, %p169;
	abs.f64 	%fd1518, %fd208;
	setp.gtu.f64	%p170, %fd1518, 0d7FF0000000000000;
	add.f64 	%fd1519, %fd208, %fd208;
	selp.f64	%fd1872, %fd1519, %fd1517, %p170;
	bra.uni 	BB0_205;

BB0_70:
	setp.eq.f64	%p60, %fd1809, 0dBFF0000000000000;
	@%p60 bra 	BB0_74;

	setp.gt.f64	%p61, %fd50, 0d3FF0000000000000;
	mov.f64 	%fd662, 0d0000000000000000;
	rcp.rn.f64 	%fd663, %fd662;
	selp.f64	%fd1814, 0d0000000000000000, %fd663, %p61;
	bra.uni 	BB0_74;

BB0_202:
	add.s32 	%r296, %r121, 2046;
	shl.b32 	%r297, %r296, 19;
	and.b32  	%r298, %r297, -1048576;
	shl.b32 	%r299, %r296, 20;
	sub.s32 	%r377, %r299, %r298;
	mov.u32 	%r300, 0;
	mov.b64 	%fd1551, {%r300, %r298};
	mul.f64 	%fd1871, %fd1871, %fd1551;

BB0_204:
	mov.u32 	%r302, 0;
	mov.b64 	%fd1552, {%r302, %r377};
	mul.f64 	%fd1872, %fd1871, %fd1552;

BB0_205:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r303}, %fd1872;
	}
	and.b32  	%r304, %r303, 2147483647;
	setp.ne.s32	%p172, %r304, 2146435072;
	@%p172 bra 	BB0_207;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r305, %temp}, %fd1872;
	}
	setp.eq.s32	%p173, %r305, 0;
	@%p173 bra 	BB0_208;

BB0_207:
	// inline asm
	fma.rn.f64 	%fd1872, %fd1872, %fd209, %fd1872;
	// inline asm

BB0_208:
	setp.neu.f64	%p174, %fd204, 0d3FF0000000000000;
	or.pred  	%p176, %p164, %p174;
	@%p176 bra 	BB0_217;

	mov.b64 	 %rd56, %fd1872;
	xor.b64  	%rd57, %rd56, -9223372036854775808;
	mov.b64 	 %fd1872, %rd57;

BB0_217:
	mul.f64 	%fd226, %fd1868, %fd1872;
	mov.f64 	%fd1873, 0d0000000000000000;
	@%p139 bra 	BB0_220;

	ld.global.f64 	%fd227, [%rd4];
	abs.f64 	%fd1566, %fd227;
	setp.gtu.f64	%p183, %fd1566, 0d7FF0000000000000;
	@%p183 bra 	BB0_220;

	sub.f64 	%fd1567, %fd227, %fd226;
	fma.rn.f64 	%fd1873, %fd1567, %fd1567, 0d0000000000000000;

BB0_220:
	@%p139 bra 	BB0_223;

	ld.global.f64 	%fd230, [%rd5];
	abs.f64 	%fd1568, %fd230;
	setp.gtu.f64	%p185, %fd1568, 0d7FF0000000000000;
	@%p185 bra 	BB0_223;

	sub.f64 	%fd1569, %fd230, %fd226;
	fma.rn.f64 	%fd1873, %fd1569, %fd1569, %fd1873;

BB0_223:
	mov.f64 	%fd1877, 0dFFF8000000000000;
	setp.le.f64	%p186, %fd1869, 0d3FF0000000000000;
	@%p186 bra 	BB0_256;

	add.f64 	%fd233, %fd1869, 0dBFF0000000000000;
	setp.eq.f64	%p187, %fd233, 0d3FF0000000000000;
	mov.f64 	%fd1876, 0d3FF0000000000000;
	@%p187 bra 	BB0_255;

	abs.f64 	%fd234, %fd233;
	setp.gtu.f64	%p188, %fd234, 0d7FF0000000000000;
	@%p188 bra 	BB0_254;
	bra.uni 	BB0_226;

BB0_254:
	add.f64 	%fd1876, %fd233, 0dBFF0000000000000;
	bra.uni 	BB0_255;

BB0_226:
	setp.eq.f64	%p189, %fd233, 0d7FF0000000000000;
	mov.f64 	%fd1572, 0dBFF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r125}, %fd1572;
	}
	@%p189 bra 	BB0_253;
	bra.uni 	BB0_227;

BB0_253:
	setp.gt.s32	%p211, %r125, -1;
	selp.f64	%fd1876, 0d7FF0000000000000, 0d0000000000000000, %p211;
	bra.uni 	BB0_255;

BB0_227:
	and.b32  	%r306, %r125, 2147483647;
	setp.ne.s32	%p190, %r306, 2146435072;
	@%p190 bra 	BB0_229;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r307, %temp}, %fd1572;
	}
	setp.eq.s32	%p191, %r307, 0;
	@%p191 bra 	BB0_251;

BB0_229:
	mov.f64 	%fd1575, 0d3FE0000000000000;
	mul.rn.f64 	%fd1576, %fd1575, %fd1572;
	cvt.rzi.f64.f64	%fd1577, %fd1576;
	mov.f64 	%fd1578, 0d4000000000000000;
	mul.rn.f64 	%fd1579, %fd1578, %fd1577;
	sub.f64 	%fd1580, %fd1572, %fd1579;
	abs.f64 	%fd235, %fd1580;
	setp.eq.f64	%p192, %fd233, 0d0000000000000000;
	@%p192 bra 	BB0_250;
	bra.uni 	BB0_230;

BB0_250:
	setp.eq.f64	%p208, %fd235, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1760, %fd233;
	mov.f64 	%fd1761, 0d0000000000000000;
	rcp.rn.f64 	%fd1762, %fd1761;
	selp.f64	%fd1876, %fd1760, %fd1762, %p208;
	bra.uni 	BB0_255;

BB0_230:
	setp.eq.f64	%p193, %fd233, 0dFFF0000000000000;
	@%p193 bra 	BB0_248;
	bra.uni 	BB0_231;

BB0_248:
	div.rn.f64 	%fd1876, %fd1572, %fd233;
	setp.neu.f64	%p207, %fd235, 0d3FF0000000000000;
	@%p207 bra 	BB0_255;

	mov.b64 	 %rd62, %fd1876;
	xor.b64  	%rd63, %rd62, -9223372036854775808;
	mov.b64 	 %fd1876, %rd63;
	bra.uni 	BB0_255;

BB0_251:
	setp.eq.f64	%p209, %fd233, 0dBFF0000000000000;
	@%p209 bra 	BB0_255;

	setp.gt.f64	%p210, %fd234, 0d3FF0000000000000;
	mov.f64 	%fd1764, 0d0000000000000000;
	rcp.rn.f64 	%fd1765, %fd1764;
	selp.f64	%fd1876, 0d0000000000000000, %fd1765, %p210;
	bra.uni 	BB0_255;

BB0_231:
	setp.geu.f64	%p194, %fd233, 0d0000000000000000;
	@%p194 bra 	BB0_233;

	cvt.rzi.f64.f64	%fd1583, %fd1572;
	setp.neu.f64	%p195, %fd1583, 0dBFF0000000000000;
	mov.f64 	%fd1876, 0dFFF8000000000000;
	@%p195 bra 	BB0_255;

BB0_233:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r379}, %fd234; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r378, hi}, %fd234; 
	}
	// inline asm
	bfe.u32 	%r380, %r379, 20, 11;
	setp.ne.s32	%p196, %r380, 0;
	@%p196 bra 	BB0_235;

	mov.f64 	%fd1588, 0d4350000000000000;
	mul.rn.f64 	%fd1587, %fd234, %fd1588;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r379}, %fd1587; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r378, hi}, %fd1587; 
	}
	// inline asm
	bfe.u32 	%r312, %r379, 20, 11;
	add.s32 	%r380, %r312, -54;

BB0_235:
	add.s32 	%r381, %r380, -1023;
	and.b32  	%r315, %r379, -2146435073;
	or.b32  	%r314, %r315, 1072693248;
	// inline asm
	mov.b64 	%fd1874, {%r378, %r314};
	// inline asm
	setp.lt.u32	%p197, %r314, 1073127583;
	@%p197 bra 	BB0_237;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r316, hi}, %fd1874; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r317}, %fd1874; 
	}
	// inline asm
	add.s32 	%r319, %r317, -1048576;
	// inline asm
	mov.b64 	%fd1874, {%r316, %r319};
	// inline asm
	add.s32 	%r381, %r380, -1022;

BB0_237:
	add.f64 	%fd1677, %fd1874, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1678, %fd1677;
	add.f64 	%fd1619, %fd1874, 0dBFF0000000000000;
	mul.rn.f64 	%fd1679, %fd1619, %fd1678;
	add.f64 	%fd1667, %fd1679, %fd1679;
	mul.rn.f64 	%fd1615, %fd1667, %fd1667;
	mov.f64 	%fd1594, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd1596, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd1593, %fd1594, %fd1615, %fd1596;
	// inline asm
	mov.f64 	%fd1600, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd1597, %fd1593, %fd1615, %fd1600;
	// inline asm
	mov.f64 	%fd1604, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd1601, %fd1597, %fd1615, %fd1604;
	// inline asm
	mov.f64 	%fd1608, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd1605, %fd1601, %fd1615, %fd1608;
	// inline asm
	mov.f64 	%fd1612, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd1609, %fd1605, %fd1615, %fd1612;
	// inline asm
	mov.f64 	%fd1616, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd1613, %fd1609, %fd1615, %fd1616;
	// inline asm
	mul.rn.f64 	%fd1680, %fd1613, %fd1615;
	sub.f64 	%fd1681, %fd1619, %fd1667;
	mul.rn.f64 	%fd1620, %fd1578, %fd1681;
	neg.f64 	%fd1618, %fd1667;
	// inline asm
	fma.rn.f64 	%fd1617, %fd1618, %fd1619, %fd1620;
	// inline asm
	mul.rn.f64 	%fd1663, %fd1678, %fd1617;
	add.f64 	%fd1683, %fd1680, 0d3FB5555555555555;
	mov.f64 	%fd1684, 0d3FB5555555555555;
	sub.f64 	%fd1685, %fd1684, %fd1683;
	add.f64 	%fd1686, %fd1680, %fd1685;
	add.f64 	%fd1687, %fd1686, 0d0000000000000000;
	add.f64 	%fd1688, %fd1687, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd1630, %fd1683, %fd1688;
	sub.f64 	%fd1689, %fd1683, %fd1630;
	add.f64 	%fd1634, %fd1688, %fd1689;
	mul.rn.f64 	%fd1690, %fd1630, %fd1667;
	neg.f64 	%fd1624, %fd1690;
	// inline asm
	fma.rn.f64 	%fd1621, %fd1630, %fd1667, %fd1624;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1625, %fd1634, %fd1663, %fd1621;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1629, %fd1630, %fd1663, %fd1625;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1633, %fd1634, %fd1667, %fd1629;
	// inline asm
	add.f64 	%fd1646, %fd1690, %fd1633;
	sub.f64 	%fd1691, %fd1690, %fd1646;
	add.f64 	%fd1650, %fd1633, %fd1691;
	mul.rn.f64 	%fd1692, %fd1646, %fd1667;
	neg.f64 	%fd1640, %fd1692;
	// inline asm
	fma.rn.f64 	%fd1637, %fd1646, %fd1667, %fd1640;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1641, %fd1650, %fd1663, %fd1637;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1645, %fd1646, %fd1663, %fd1641;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1649, %fd1650, %fd1667, %fd1645;
	// inline asm
	add.f64 	%fd1662, %fd1692, %fd1649;
	sub.f64 	%fd1693, %fd1692, %fd1662;
	add.f64 	%fd1666, %fd1649, %fd1693;
	mul.rn.f64 	%fd1694, %fd1662, %fd1667;
	neg.f64 	%fd1656, %fd1694;
	// inline asm
	fma.rn.f64 	%fd1653, %fd1662, %fd1667, %fd1656;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1657, %fd1666, %fd1663, %fd1653;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1661, %fd1662, %fd1663, %fd1657;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1665, %fd1666, %fd1667, %fd1661;
	// inline asm
	add.f64 	%fd1695, %fd1694, %fd1665;
	sub.f64 	%fd1696, %fd1694, %fd1695;
	add.f64 	%fd1697, %fd1665, %fd1696;
	add.f64 	%fd1698, %fd1667, %fd1695;
	sub.f64 	%fd1699, %fd1667, %fd1698;
	add.f64 	%fd1700, %fd1695, %fd1699;
	add.f64 	%fd1701, %fd1697, %fd1700;
	add.f64 	%fd1702, %fd1663, %fd1701;
	add.f64 	%fd1703, %fd1698, %fd1702;
	sub.f64 	%fd1704, %fd1698, %fd1703;
	add.f64 	%fd1705, %fd1702, %fd1704;
	cvt.rn.f64.s32	%fd1706, %r381;
	mov.f64 	%fd1707, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd1708, %fd1706, %fd1707;
	mov.f64 	%fd1709, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd1710, %fd1706, %fd1709;
	add.f64 	%fd1711, %fd1708, %fd1703;
	sub.f64 	%fd1712, %fd1708, %fd1711;
	add.f64 	%fd1713, %fd1703, %fd1712;
	add.f64 	%fd1714, %fd1705, %fd1713;
	add.f64 	%fd1715, %fd1710, %fd1714;
	add.f64 	%fd1670, %fd1711, %fd1715;
	sub.f64 	%fd1716, %fd1711, %fd1670;
	add.f64 	%fd1674, %fd1715, %fd1716;
	mul.rn.f64 	%fd1717, %fd1670, %fd1572;
	neg.f64 	%fd1672, %fd1717;
	// inline asm
	fma.rn.f64 	%fd1669, %fd1670, %fd1572, %fd1672;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1673, %fd1674, %fd1572, %fd1669;
	// inline asm
	add.f64 	%fd239, %fd1717, %fd1673;
	sub.f64 	%fd1718, %fd1717, %fd239;
	add.f64 	%fd240, %fd1673, %fd1718;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r138}, %fd239;
	}
	mov.b32 	 %f11, %r138;
	abs.f32 	%f12, %f11;
	setp.lt.f32	%p198, %f12, 0f40874911;
	@%p198 bra 	BB0_239;
	bra.uni 	BB0_238;

BB0_239:
	mov.f64 	%fd1722, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1723, %fd239, %fd1722;
	mov.f64 	%fd1724, 0d4338000000000000;
	add.rn.f64 	%fd1725, %fd1723, %fd1724;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd1725;
	}
	mov.f64 	%fd1726, 0dC338000000000000;
	add.rn.f64 	%fd1727, %fd1725, %fd1726;
	mov.f64 	%fd1728, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1729, %fd1727, %fd1728, %fd239;
	mov.f64 	%fd1730, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd1731, %fd1727, %fd1730, %fd1729;
	mov.f64 	%fd1732, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1733, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1734, %fd1733, %fd1731, %fd1732;
	mov.f64 	%fd1735, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1736, %fd1734, %fd1731, %fd1735;
	mov.f64 	%fd1737, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1738, %fd1736, %fd1731, %fd1737;
	mov.f64 	%fd1739, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1740, %fd1738, %fd1731, %fd1739;
	mov.f64 	%fd1741, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1742, %fd1740, %fd1731, %fd1741;
	mov.f64 	%fd1743, 0d3F81111111122322;
	fma.rn.f64 	%fd1744, %fd1742, %fd1731, %fd1743;
	mov.f64 	%fd1745, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1746, %fd1744, %fd1731, %fd1745;
	mov.f64 	%fd1747, 0d3FC5555555555511;
	fma.rn.f64 	%fd1748, %fd1746, %fd1731, %fd1747;
	mov.f64 	%fd1749, 0d3FE000000000000B;
	fma.rn.f64 	%fd1750, %fd1748, %fd1731, %fd1749;
	mov.f64 	%fd1751, 0d3FF0000000000000;
	fma.rn.f64 	%fd1752, %fd1750, %fd1731, %fd1751;
	fma.rn.f64 	%fd1875, %fd1752, %fd1731, %fd1751;
	abs.s32 	%r320, %r139;
	setp.lt.s32	%p201, %r320, 1023;
	@%p201 bra 	BB0_241;
	bra.uni 	BB0_240;

BB0_241:
	shl.b32 	%r326, %r139, 20;
	add.s32 	%r382, %r326, 1072693248;
	bra.uni 	BB0_242;

BB0_58:
	setp.lt.s32	%p51, %r41, 0;
	selp.f64	%fd620, 0d0000000000000000, 0d7FF0000000000000, %p51;
	abs.f64 	%fd621, %fd55;
	setp.gtu.f64	%p52, %fd621, 0d7FF0000000000000;
	add.f64 	%fd622, %fd55, %fd55;
	selp.f64	%fd1814, %fd622, %fd620, %p52;
	bra.uni 	BB0_63;

BB0_238:
	setp.lt.s32	%p199, %r138, 0;
	selp.f64	%fd1719, 0d0000000000000000, 0d7FF0000000000000, %p199;
	abs.f64 	%fd1720, %fd239;
	setp.gtu.f64	%p200, %fd1720, 0d7FF0000000000000;
	add.f64 	%fd1721, %fd239, %fd239;
	selp.f64	%fd1876, %fd1721, %fd1719, %p200;
	bra.uni 	BB0_243;

BB0_60:
	add.s32 	%r190, %r42, 2046;
	shl.b32 	%r191, %r190, 19;
	and.b32  	%r192, %r191, -1048576;
	shl.b32 	%r193, %r190, 20;
	sub.s32 	%r342, %r193, %r192;
	mov.u32 	%r194, 0;
	mov.b64 	%fd654, {%r194, %r192};
	mul.f64 	%fd1813, %fd1813, %fd654;

BB0_62:
	mov.u32 	%r196, 0;
	mov.b64 	%fd655, {%r196, %r342};
	mul.f64 	%fd1814, %fd1813, %fd655;

BB0_63:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r197}, %fd1814;
	}
	and.b32  	%r198, %r197, 2147483647;
	setp.ne.s32	%p54, %r198, 2146435072;
	@%p54 bra 	BB0_65;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r199, %temp}, %fd1814;
	}
	setp.eq.s32	%p55, %r199, 0;
	@%p55 bra 	BB0_66;

BB0_65:
	// inline asm
	fma.rn.f64 	%fd1814, %fd1814, %fd56, %fd1814;
	// inline asm

BB0_66:
	setp.neu.f64	%p56, %fd51, 0d3FF0000000000000;
	or.pred  	%p58, %p46, %p56;
	@%p58 bra 	BB0_74;

	mov.b64 	 %rd26, %fd1814;
	xor.b64  	%rd27, %rd26, -9223372036854775808;
	mov.b64 	 %fd1814, %rd27;
	bra.uni 	BB0_74;

BB0_240:
	add.s32 	%r321, %r139, 2046;
	shl.b32 	%r322, %r321, 19;
	and.b32  	%r323, %r322, -1048576;
	shl.b32 	%r324, %r321, 20;
	sub.s32 	%r382, %r324, %r323;
	mov.u32 	%r325, 0;
	mov.b64 	%fd1753, {%r325, %r323};
	mul.f64 	%fd1875, %fd1875, %fd1753;

BB0_242:
	mov.u32 	%r327, 0;
	mov.b64 	%fd1754, {%r327, %r382};
	mul.f64 	%fd1876, %fd1875, %fd1754;

BB0_243:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r328}, %fd1876;
	}
	and.b32  	%r329, %r328, 2147483647;
	setp.ne.s32	%p202, %r329, 2146435072;
	@%p202 bra 	BB0_245;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r330, %temp}, %fd1876;
	}
	setp.eq.s32	%p203, %r330, 0;
	@%p203 bra 	BB0_246;

BB0_245:
	// inline asm
	fma.rn.f64 	%fd1876, %fd1876, %fd240, %fd1876;
	// inline asm

BB0_246:
	setp.neu.f64	%p204, %fd235, 0d3FF0000000000000;
	or.pred  	%p206, %p194, %p204;
	@%p206 bra 	BB0_255;

	mov.b64 	 %rd60, %fd1876;
	xor.b64  	%rd61, %rd60, -9223372036854775808;
	mov.b64 	 %fd1876, %rd61;

BB0_255:
	mul.f64 	%fd1877, %fd1873, %fd1876;

BB0_256:
	ld.param.u64 	%rd69, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_0];
	add.f64 	%fd1766, %fd194, %fd1877;
	sub.f64 	%fd1767, %fd1766, %fd1862;
	add.f64 	%fd1768, %fd152, %fd1767;
	add.f64 	%fd1769, %fd1815, %fd1768;
	add.s64 	%rd65, %rd69, %rd54;
	st.global.f64 	[%rd65], %fd1769;
	ret;
}


  